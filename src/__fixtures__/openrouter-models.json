{
  "lastUpdated": "2026-02-13T08:49:09Z",
  "data": [
    {
      "id": "minimax/minimax-m2.5",
      "canonical_slug": "minimax/minimax-m2.5-20260211",
      "hugging_face_id": "MiniMaxAI/MiniMax-M2.5",
      "name": "MiniMax: MiniMax M2.5",
      "created": 1770908502,
      "context_length": 204800,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000003",
        "completion": "0.0000012",
        "input_cache_read": "0.00000003"
      },
      "top_provider": {
        "context_length": 204800,
        "max_completion_tokens": 131072,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "z-ai/glm-5",
      "canonical_slug": "z-ai/glm-5-20260211",
      "hugging_face_id": "zai-org/GLM-5",
      "name": "Z.ai: GLM 5",
      "created": 1770829182,
      "context_length": 202752,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000008",
        "completion": "0.00000256",
        "input_cache_read": "0.00000016"
      },
      "top_provider": {
        "context_length": 202752,
        "max_completion_tokens": 131072,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-max-thinking",
      "canonical_slug": "qwen/qwen3-max-thinking-20260123",
      "hugging_face_id": null,
      "name": "Qwen: Qwen3 Max Thinking",
      "created": 1770671901,
      "context_length": 262144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000012",
        "completion": "0.000006"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openrouter/aurora-alpha",
      "canonical_slug": "openrouter/aurora-alpha",
      "hugging_face_id": "",
      "name": "Aurora Alpha",
      "created": 1770611225,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0",
        "request": "0",
        "image": "0",
        "web_search": "0",
        "internal_reasoning": "0"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 50000,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "reasoning_effort",
        "response_format",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "anthropic/claude-opus-4.6",
      "canonical_slug": "anthropic/claude-4.6-opus-20260205",
      "hugging_face_id": "",
      "name": "Anthropic: Claude Opus 4.6",
      "created": 1770219050,
      "context_length": 1000000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000005",
        "completion": "0.000025",
        "web_search": "0.01",
        "input_cache_read": "0.0000005",
        "input_cache_write": "0.00000625"
      },
      "top_provider": {
        "context_length": 1000000,
        "max_completion_tokens": 128000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
        "verbosity"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-coder-next",
      "canonical_slug": "qwen/qwen3-coder-next-2025-02-03",
      "hugging_face_id": "Qwen/Qwen3-Coder-Next",
      "name": "Qwen: Qwen3 Coder Next",
      "created": 1770164101,
      "context_length": 262144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000007",
        "completion": "0.0000003",
        "input_cache_read": "0.000000035"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openrouter/free",
      "canonical_slug": "openrouter/free",
      "hugging_face_id": "",
      "name": "Free Models Router",
      "created": 1769917427,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Router",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": null,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "stepfun/step-3.5-flash:free",
      "canonical_slug": "stepfun/step-3.5-flash",
      "hugging_face_id": "stepfun-ai/Step-3.5-Flash",
      "name": "StepFun: Step 3.5 Flash (free)",
      "created": 1769728337,
      "context_length": 256000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 256000,
        "max_completion_tokens": 256000,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "stepfun/step-3.5-flash",
      "canonical_slug": "stepfun/step-3.5-flash",
      "hugging_face_id": "stepfun-ai/Step-3.5-Flash",
      "name": "StepFun: Step 3.5 Flash",
      "created": 1769728337,
      "context_length": 256000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000001",
        "completion": "0.0000003",
        "input_cache_read": "0.00000002"
      },
      "top_provider": {
        "context_length": 256000,
        "max_completion_tokens": 256000,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "arcee-ai/trinity-large-preview:free",
      "canonical_slug": "arcee-ai/trinity-large-preview",
      "hugging_face_id": "arcee-ai/Trinity-Large-Preview",
      "name": "Arcee AI: Trinity Large Preview (free)",
      "created": 1769552670,
      "context_length": 131000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 131000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "structured_outputs",
        "temperature",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "moonshotai/kimi-k2.5",
      "canonical_slug": "moonshotai/kimi-k2.5-0127",
      "hugging_face_id": "moonshotai/Kimi-K2.5",
      "name": "MoonshotAI: Kimi K2.5",
      "created": 1769487076,
      "context_length": 262144,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000045",
        "completion": "0.00000225",
        "input_cache_read": "0.000000070000002"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "parallel_tool_calls",
        "presence_penalty",
        "reasoning",
        "reasoning_effort",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "upstage/solar-pro-3:free",
      "canonical_slug": "upstage/solar-pro-3",
      "hugging_face_id": "",
      "name": "Upstage: Solar Pro 3 (free)",
      "created": 1769481200,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools"
      ],
      "expiration_date": "2026-03-02"
    },
    {
      "id": "minimax/minimax-m2-her",
      "canonical_slug": "minimax/minimax-m2-her-20260123",
      "hugging_face_id": "",
      "name": "MiniMax: MiniMax M2-her",
      "created": 1769177239,
      "context_length": 65536,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000003",
        "completion": "0.0000012",
        "input_cache_read": "0.00000003"
      },
      "top_provider": {
        "context_length": 65536,
        "max_completion_tokens": 2048,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "writer/palmyra-x5",
      "canonical_slug": "writer/palmyra-x5-20250428",
      "hugging_face_id": "",
      "name": "Writer: Palmyra X5",
      "created": 1769003823,
      "context_length": 1040000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000006",
        "completion": "0.000006"
      },
      "top_provider": {
        "context_length": 1040000,
        "max_completion_tokens": 8192,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "liquid/lfm-2.5-1.2b-thinking:free",
      "canonical_slug": "liquid/lfm-2.5-1.2b-thinking-20260120",
      "hugging_face_id": "LiquidAI/LFM2.5-1.2B-Thinking",
      "name": "LiquidAI: LFM2.5-1.2B-Thinking (free)",
      "created": 1768927527,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "liquid/lfm-2.5-1.2b-instruct:free",
      "canonical_slug": "liquid/lfm-2.5-1.2b-instruct-20260120",
      "hugging_face_id": "LiquidAI/LFM2.5-1.2B-Instruct",
      "name": "LiquidAI: LFM2.5-1.2B-Instruct (free)",
      "created": 1768927521,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-audio",
      "canonical_slug": "openai/gpt-audio",
      "hugging_face_id": "",
      "name": "OpenAI: GPT Audio",
      "created": 1768862569,
      "context_length": 128000,
      "architecture": {
        "modality": "text+audio->text+audio",
        "input_modalities": [
          "text",
          "audio"
        ],
        "output_modalities": [
          "text",
          "audio"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000025",
        "completion": "0.00001",
        "audio": "0.000032"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-audio-mini",
      "canonical_slug": "openai/gpt-audio-mini",
      "hugging_face_id": "",
      "name": "OpenAI: GPT Audio Mini",
      "created": 1768859419,
      "context_length": 128000,
      "architecture": {
        "modality": "text+audio->text+audio",
        "input_modalities": [
          "text",
          "audio"
        ],
        "output_modalities": [
          "text",
          "audio"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000006",
        "completion": "0.0000024",
        "audio": "0.0000006"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "z-ai/glm-4.7-flash",
      "canonical_slug": "z-ai/glm-4.7-flash-20260119",
      "hugging_face_id": "zai-org/GLM-4.7-Flash",
      "name": "Z.ai: GLM 4.7 Flash",
      "created": 1768833913,
      "context_length": 202752,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000006",
        "completion": "0.0000004",
        "input_cache_read": "0.0000000100000002"
      },
      "top_provider": {
        "context_length": 202752,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-5.2-codex",
      "canonical_slug": "openai/gpt-5.2-codex-20260114",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-5.2-Codex",
      "created": 1768409315,
      "context_length": 400000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000175",
        "completion": "0.000014",
        "web_search": "0.01",
        "input_cache_read": "0.000000175"
      },
      "top_provider": {
        "context_length": 400000,
        "max_completion_tokens": 128000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "allenai/molmo-2-8b",
      "canonical_slug": "allenai/molmo-2-8b-20260109",
      "hugging_face_id": "allenai/Molmo2-8B",
      "name": "AllenAI: Molmo2 8B",
      "created": 1767996672,
      "context_length": 36864,
      "architecture": {
        "modality": "text+image+video->text",
        "input_modalities": [
          "text",
          "image",
          "video"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000002",
        "completion": "0.0000002"
      },
      "top_provider": {
        "context_length": 36864,
        "max_completion_tokens": 36864,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "allenai/olmo-3.1-32b-instruct",
      "canonical_slug": "allenai/olmo-3.1-32b-instruct-20251215",
      "hugging_face_id": "allenai/Olmo-3.1-32B-Instruct",
      "name": "AllenAI: Olmo 3.1 32B Instruct",
      "created": 1767728554,
      "context_length": 65536,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000002",
        "completion": "0.0000006"
      },
      "top_provider": {
        "context_length": 65536,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "bytedance-seed/seed-1.6-flash",
      "canonical_slug": "bytedance-seed/seed-1.6-flash-20250625",
      "hugging_face_id": "",
      "name": "ByteDance Seed: Seed 1.6 Flash",
      "created": 1766505011,
      "context_length": 262144,
      "architecture": {
        "modality": "text+image+video->text",
        "input_modalities": [
          "image",
          "text",
          "video"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000000075",
        "completion": "0.0000003"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "bytedance-seed/seed-1.6",
      "canonical_slug": "bytedance-seed/seed-1.6-20250625",
      "hugging_face_id": "",
      "name": "ByteDance Seed: Seed 1.6",
      "created": 1766504997,
      "context_length": 262144,
      "architecture": {
        "modality": "text+image+video->text",
        "input_modalities": [
          "image",
          "text",
          "video"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000025",
        "completion": "0.000002"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "minimax/minimax-m2.1",
      "canonical_slug": "minimax/minimax-m2.1",
      "hugging_face_id": "MiniMaxAI/MiniMax-M2.1",
      "name": "MiniMax: MiniMax M2.1",
      "created": 1766454997,
      "context_length": 196608,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000027",
        "completion": "0.00000095",
        "input_cache_read": "0.0000000299999997"
      },
      "top_provider": {
        "context_length": 196608,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "z-ai/glm-4.7",
      "canonical_slug": "z-ai/glm-4.7-20251222",
      "hugging_face_id": "zai-org/GLM-4.7",
      "name": "Z.ai: GLM 4.7",
      "created": 1766378014,
      "context_length": 202752,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000004",
        "completion": "0.0000015",
        "input_cache_read": "0.0000002"
      },
      "top_provider": {
        "context_length": 202752,
        "max_completion_tokens": 65535,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "parallel_tool_calls",
        "presence_penalty",
        "reasoning",
        "reasoning_effort",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemini-3-flash-preview",
      "canonical_slug": "google/gemini-3-flash-preview-20251217",
      "hugging_face_id": "",
      "name": "Google: Gemini 3 Flash Preview",
      "created": 1765987078,
      "context_length": 1048576,
      "architecture": {
        "modality": "text+image+file+audio+video->text",
        "input_modalities": [
          "text",
          "image",
          "file",
          "audio",
          "video"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000005",
        "completion": "0.000003",
        "image": "0.0000005",
        "audio": "0.000001",
        "internal_reasoning": "0.000003",
        "input_cache_read": "0.00000005",
        "input_cache_write": "0.00000008333333333333334"
      },
      "top_provider": {
        "context_length": 1048576,
        "max_completion_tokens": 65535,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mistral-small-creative",
      "canonical_slug": "mistralai/mistral-small-creative-20251216",
      "hugging_face_id": null,
      "name": "Mistral: Mistral Small Creative",
      "created": 1765908653,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000001",
        "completion": "0.0000003"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "allenai/olmo-3.1-32b-think",
      "canonical_slug": "allenai/olmo-3.1-32b-think-20251215",
      "hugging_face_id": "allenai/Olmo-3.1-32B-Think",
      "name": "AllenAI: Olmo 3.1 32B Think",
      "created": 1765907719,
      "context_length": 65536,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000015",
        "completion": "0.0000005"
      },
      "top_provider": {
        "context_length": 65536,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "xiaomi/mimo-v2-flash",
      "canonical_slug": "xiaomi/mimo-v2-flash-20251210",
      "hugging_face_id": "XiaomiMiMo/MiMo-V2-Flash",
      "name": "Xiaomi: MiMo-V2-Flash",
      "created": 1765731308,
      "context_length": 262144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000009",
        "completion": "0.00000029",
        "input_cache_read": "0.000000045"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "nvidia/nemotron-3-nano-30b-a3b:free",
      "canonical_slug": "nvidia/nemotron-3-nano-30b-a3b",
      "hugging_face_id": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "name": "NVIDIA: Nemotron 3 Nano 30B A3B (free)",
      "created": 1765731275,
      "context_length": 256000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 256000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "seed",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "nvidia/nemotron-3-nano-30b-a3b",
      "canonical_slug": "nvidia/nemotron-3-nano-30b-a3b",
      "hugging_face_id": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "name": "NVIDIA: Nemotron 3 Nano 30B A3B",
      "created": 1765731275,
      "context_length": 262144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000005",
        "completion": "0.0000002"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-5.2-chat",
      "canonical_slug": "openai/gpt-5.2-chat-20251211",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-5.2 Chat",
      "created": 1765389783,
      "context_length": 128000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "file",
          "image",
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000175",
        "completion": "0.000014",
        "web_search": "0.01",
        "input_cache_read": "0.000000175"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-5.2-pro",
      "canonical_slug": "openai/gpt-5.2-pro-20251211",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-5.2 Pro",
      "created": 1765389780,
      "context_length": 400000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "image",
          "text",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000021",
        "completion": "0.000168",
        "web_search": "0.01"
      },
      "top_provider": {
        "context_length": 400000,
        "max_completion_tokens": 128000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-5.2",
      "canonical_slug": "openai/gpt-5.2-20251211",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-5.2",
      "created": 1765389775,
      "context_length": 400000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "file",
          "image",
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000175",
        "completion": "0.000014",
        "web_search": "0.01",
        "input_cache_read": "0.000000175"
      },
      "top_provider": {
        "context_length": 400000,
        "max_completion_tokens": 128000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/devstral-2512",
      "canonical_slug": "mistralai/devstral-2512",
      "hugging_face_id": "mistralai/Devstral-2-123B-Instruct-2512",
      "name": "Mistral: Devstral 2 2512",
      "created": 1765285419,
      "context_length": 262144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000005",
        "completion": "0.00000022",
        "input_cache_read": "0.000000025"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "relace/relace-search",
      "canonical_slug": "relace/relace-search-20251208",
      "hugging_face_id": null,
      "name": "Relace: Relace Search",
      "created": 1765213560,
      "context_length": 256000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000001",
        "completion": "0.000003"
      },
      "top_provider": {
        "context_length": 256000,
        "max_completion_tokens": 128000,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "z-ai/glm-4.6v",
      "canonical_slug": "z-ai/glm-4.6-20251208",
      "hugging_face_id": "zai-org/GLM-4.6V",
      "name": "Z.ai: GLM 4.6V",
      "created": 1765207462,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image+video->text",
        "input_modalities": [
          "image",
          "text",
          "video"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000003",
        "completion": "0.0000009"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 131072,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "nex-agi/deepseek-v3.1-nex-n1",
      "canonical_slug": "nex-agi/deepseek-v3.1-nex-n1",
      "hugging_face_id": "nex-agi/DeepSeek-V3.1-Nex-N1",
      "name": "Nex AGI: DeepSeek V3.1 Nex N1",
      "created": 1765204393,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "DeepSeek",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000027",
        "completion": "0.000001"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 163840,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "response_format",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "essentialai/rnj-1-instruct",
      "canonical_slug": "essentialai/rnj-1-instruct",
      "hugging_face_id": "EssentialAI/rnj-1-instruct",
      "name": "EssentialAI: Rnj 1 Instruct",
      "created": 1765094847,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000015",
        "completion": "0.00000015"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openrouter/bodybuilder",
      "canonical_slug": "openrouter/bodybuilder",
      "hugging_face_id": "",
      "name": "Body Builder (beta)",
      "created": 1764903653,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Router",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "-1",
        "completion": "-1"
      },
      "top_provider": {
        "context_length": null,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-5.1-codex-max",
      "canonical_slug": "openai/gpt-5.1-codex-max-20251204",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-5.1-Codex-Max",
      "created": 1764878934,
      "context_length": 400000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000125",
        "completion": "0.00001",
        "web_search": "0.01",
        "input_cache_read": "0.000000125"
      },
      "top_provider": {
        "context_length": 400000,
        "max_completion_tokens": 128000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "amazon/nova-2-lite-v1",
      "canonical_slug": "amazon/nova-2-lite-v1",
      "hugging_face_id": "",
      "name": "Amazon: Nova 2 Lite",
      "created": 1764696672,
      "context_length": 1000000,
      "architecture": {
        "modality": "text+image+file+video->text",
        "input_modalities": [
          "text",
          "image",
          "video",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Nova",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000003",
        "completion": "0.0000025"
      },
      "top_provider": {
        "context_length": 1000000,
        "max_completion_tokens": 65535,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/ministral-14b-2512",
      "canonical_slug": "mistralai/ministral-14b-2512",
      "hugging_face_id": "mistralai/Ministral-3-14B-Instruct-2512",
      "name": "Mistral: Ministral 3 14B 2512",
      "created": 1764681735,
      "context_length": 262144,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000002",
        "completion": "0.0000002"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/ministral-8b-2512",
      "canonical_slug": "mistralai/ministral-8b-2512",
      "hugging_face_id": "mistralai/Ministral-3-8B-Instruct-2512",
      "name": "Mistral: Ministral 3 8B 2512",
      "created": 1764681654,
      "context_length": 262144,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000015",
        "completion": "0.00000015"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/ministral-3b-2512",
      "canonical_slug": "mistralai/ministral-3b-2512",
      "hugging_face_id": "mistralai/Ministral-3-3B-Instruct-2512",
      "name": "Mistral: Ministral 3 3B 2512",
      "created": 1764681560,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000001",
        "completion": "0.0000001"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mistral-large-2512",
      "canonical_slug": "mistralai/mistral-large-2512",
      "hugging_face_id": "",
      "name": "Mistral: Mistral Large 3 2512",
      "created": 1764624472,
      "context_length": 262144,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000005",
        "completion": "0.0000015"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "arcee-ai/trinity-mini:free",
      "canonical_slug": "arcee-ai/trinity-mini-20251201",
      "hugging_face_id": "arcee-ai/Trinity-Mini",
      "name": "Arcee AI: Trinity Mini (free)",
      "created": 1764601720,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "arcee-ai/trinity-mini",
      "canonical_slug": "arcee-ai/trinity-mini-20251201",
      "hugging_face_id": "arcee-ai/Trinity-Mini",
      "name": "Arcee AI: Trinity Mini",
      "created": 1764601720,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000000045",
        "completion": "0.00000015"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 131072,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "deepseek/deepseek-v3.2-speciale",
      "canonical_slug": "deepseek/deepseek-v3.2-speciale-20251201",
      "hugging_face_id": "deepseek-ai/DeepSeek-V3.2-Speciale",
      "name": "DeepSeek: DeepSeek V3.2 Speciale",
      "created": 1764594837,
      "context_length": 163840,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "DeepSeek",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000027",
        "completion": "0.00000041",
        "input_cache_read": "0.000000135"
      },
      "top_provider": {
        "context_length": 163840,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "deepseek/deepseek-v3.2",
      "canonical_slug": "deepseek/deepseek-v3.2-20251201",
      "hugging_face_id": "deepseek-ai/DeepSeek-V3.2",
      "name": "DeepSeek: DeepSeek V3.2",
      "created": 1764594642,
      "context_length": 163840,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "DeepSeek",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000025",
        "completion": "0.00000038",
        "input_cache_read": "0.000000125"
      },
      "top_provider": {
        "context_length": 163840,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "prime-intellect/intellect-3",
      "canonical_slug": "prime-intellect/intellect-3-20251126",
      "hugging_face_id": "PrimeIntellect/INTELLECT-3-FP8",
      "name": "Prime Intellect: INTELLECT-3",
      "created": 1764212534,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000002",
        "completion": "0.0000011"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 131072,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "tngtech/tng-r1t-chimera:free",
      "canonical_slug": "tngtech/tng-r1t-chimera",
      "hugging_face_id": null,
      "name": "TNG: R1T Chimera (free)",
      "created": 1764184161,
      "context_length": 163840,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 163840,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "tngtech/tng-r1t-chimera",
      "canonical_slug": "tngtech/tng-r1t-chimera",
      "hugging_face_id": null,
      "name": "TNG: R1T Chimera",
      "created": 1764184161,
      "context_length": 163840,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000025",
        "completion": "0.00000085",
        "input_cache_read": "0.000000125"
      },
      "top_provider": {
        "context_length": 163840,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "anthropic/claude-opus-4.5",
      "canonical_slug": "anthropic/claude-4.5-opus-20251124",
      "hugging_face_id": "",
      "name": "Anthropic: Claude Opus 4.5",
      "created": 1764010580,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "file",
          "image",
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000005",
        "completion": "0.000025",
        "web_search": "0.01",
        "input_cache_read": "0.0000005",
        "input_cache_write": "0.00000625"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 64000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "verbosity"
      ],
      "expiration_date": null
    },
    {
      "id": "allenai/olmo-3-32b-think",
      "canonical_slug": "allenai/olmo-3-32b-think-20251121",
      "hugging_face_id": "allenai/Olmo-3-32B-Think",
      "name": "AllenAI: Olmo 3 32B Think",
      "created": 1763758276,
      "context_length": 65536,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000015",
        "completion": "0.0000005"
      },
      "top_provider": {
        "context_length": 65536,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "allenai/olmo-3-7b-instruct",
      "canonical_slug": "allenai/olmo-3-7b-instruct-20251121",
      "hugging_face_id": "allenai/Olmo-3-7B-Instruct",
      "name": "AllenAI: Olmo 3 7B Instruct",
      "created": 1763758273,
      "context_length": 65536,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000001",
        "completion": "0.0000002"
      },
      "top_provider": {
        "context_length": 65536,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "allenai/olmo-3-7b-think",
      "canonical_slug": "allenai/olmo-3-7b-think-20251121",
      "hugging_face_id": "allenai/Olmo-3-7B-Think",
      "name": "AllenAI: Olmo 3 7B Think",
      "created": 1763758270,
      "context_length": 65536,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000012",
        "completion": "0.0000002"
      },
      "top_provider": {
        "context_length": 65536,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemini-3-pro-image-preview",
      "canonical_slug": "google/gemini-3-pro-image-preview-20251120",
      "hugging_face_id": "",
      "name": "Google: Nano Banana Pro (Gemini 3 Pro Image Preview)",
      "created": 1763653797,
      "context_length": 65536,
      "architecture": {
        "modality": "text+image->text+image",
        "input_modalities": [
          "image",
          "text"
        ],
        "output_modalities": [
          "image",
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000002",
        "completion": "0.000012",
        "image": "0.000002",
        "audio": "0.000002",
        "internal_reasoning": "0.000012",
        "input_cache_read": "0.0000002",
        "input_cache_write": "0.000000375"
      },
      "top_provider": {
        "context_length": 65536,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "x-ai/grok-4.1-fast",
      "canonical_slug": "x-ai/grok-4.1-fast",
      "hugging_face_id": "",
      "name": "xAI: Grok 4.1 Fast",
      "created": 1763587502,
      "context_length": 2000000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Grok",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000002",
        "completion": "0.0000005",
        "web_search": "0.005",
        "input_cache_read": "0.00000005"
      },
      "top_provider": {
        "context_length": 2000000,
        "max_completion_tokens": 30000,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "logprobs",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemini-3-pro-preview",
      "canonical_slug": "google/gemini-3-pro-preview-20251117",
      "hugging_face_id": "",
      "name": "Google: Gemini 3 Pro Preview",
      "created": 1763474668,
      "context_length": 1048576,
      "architecture": {
        "modality": "text+image+file+audio+video->text",
        "input_modalities": [
          "text",
          "image",
          "file",
          "audio",
          "video"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000002",
        "completion": "0.000012",
        "image": "0.000002",
        "audio": "0.000002",
        "internal_reasoning": "0.000012",
        "input_cache_read": "0.0000002",
        "input_cache_write": "0.000000375"
      },
      "top_provider": {
        "context_length": 1048576,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "deepcogito/cogito-v2.1-671b",
      "canonical_slug": "deepcogito/cogito-v2.1-671b-20251118",
      "hugging_face_id": "",
      "name": "Deep Cogito: Cogito v2.1 671B",
      "created": 1763071233,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000125",
        "completion": "0.00000125"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-5.1",
      "canonical_slug": "openai/gpt-5.1-20251113",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-5.1",
      "created": 1763060305,
      "context_length": 400000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "image",
          "text",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000125",
        "completion": "0.00001",
        "web_search": "0.01",
        "input_cache_read": "0.000000125"
      },
      "top_provider": {
        "context_length": 400000,
        "max_completion_tokens": 128000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-5.1-chat",
      "canonical_slug": "openai/gpt-5.1-chat-20251113",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-5.1 Chat",
      "created": 1763060302,
      "context_length": 128000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "file",
          "image",
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000125",
        "completion": "0.00001",
        "web_search": "0.01",
        "input_cache_read": "0.000000125"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-5.1-codex",
      "canonical_slug": "openai/gpt-5.1-codex-20251113",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-5.1-Codex",
      "created": 1763060298,
      "context_length": 400000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000125",
        "completion": "0.00001",
        "input_cache_read": "0.000000125"
      },
      "top_provider": {
        "context_length": 400000,
        "max_completion_tokens": 128000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-5.1-codex-mini",
      "canonical_slug": "openai/gpt-5.1-codex-mini-20251113",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-5.1-Codex-Mini",
      "created": 1763057820,
      "context_length": 400000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "image",
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000025",
        "completion": "0.000002",
        "input_cache_read": "0.000000025"
      },
      "top_provider": {
        "context_length": 400000,
        "max_completion_tokens": 100000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "kwaipilot/kat-coder-pro",
      "canonical_slug": "kwaipilot/kat-coder-pro-v1",
      "hugging_face_id": "",
      "name": "Kwaipilot: KAT-Coder-Pro V1",
      "created": 1762745912,
      "context_length": 256000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000000207",
        "completion": "0.000000828",
        "input_cache_read": "0.0000000414"
      },
      "top_provider": {
        "context_length": 256000,
        "max_completion_tokens": 128000,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "moonshotai/kimi-k2-thinking",
      "canonical_slug": "moonshotai/kimi-k2-thinking-20251106",
      "hugging_face_id": "moonshotai/Kimi-K2-Thinking",
      "name": "MoonshotAI: Kimi K2 Thinking",
      "created": 1762440622,
      "context_length": 262144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000004",
        "completion": "0.00000175",
        "input_cache_read": "0.0000002"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": 65535,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "amazon/nova-premier-v1",
      "canonical_slug": "amazon/nova-premier-v1",
      "hugging_face_id": "",
      "name": "Amazon: Nova Premier 1.0",
      "created": 1761950332,
      "context_length": 1000000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Nova",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000025",
        "completion": "0.0000125",
        "input_cache_read": "0.000000625"
      },
      "top_provider": {
        "context_length": 1000000,
        "max_completion_tokens": 32000,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "perplexity/sonar-pro-search",
      "canonical_slug": "perplexity/sonar-pro-search",
      "hugging_face_id": "",
      "name": "Perplexity: Sonar Pro Search",
      "created": 1761854366,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000003",
        "completion": "0.000015",
        "web_search": "0.018"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 8000,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p",
        "web_search_options"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/voxtral-small-24b-2507",
      "canonical_slug": "mistralai/voxtral-small-24b-2507",
      "hugging_face_id": "mistralai/Voxtral-Small-24B-2507",
      "name": "Mistral: Voxtral Small 24B 2507",
      "created": 1761835144,
      "context_length": 32000,
      "architecture": {
        "modality": "text+audio->text",
        "input_modalities": [
          "text",
          "audio"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000001",
        "completion": "0.0000003",
        "audio": "0.0001"
      },
      "top_provider": {
        "context_length": 32000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-oss-safeguard-20b",
      "canonical_slug": "openai/gpt-oss-safeguard-20b",
      "hugging_face_id": "openai/gpt-oss-safeguard-20b",
      "name": "OpenAI: gpt-oss-safeguard-20b",
      "created": 1761752836,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000000075",
        "completion": "0.0000003",
        "input_cache_read": "0.000000037"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "nvidia/nemotron-nano-12b-v2-vl:free",
      "canonical_slug": "nvidia/nemotron-nano-12b-v2-vl",
      "hugging_face_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2-VL-BF16",
      "name": "NVIDIA: Nemotron Nano 12B 2 VL (free)",
      "created": 1761675565,
      "context_length": 128000,
      "architecture": {
        "modality": "text+image+video->text",
        "input_modalities": [
          "image",
          "text",
          "video"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 128000,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "seed",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "nvidia/nemotron-nano-12b-v2-vl",
      "canonical_slug": "nvidia/nemotron-nano-12b-v2-vl",
      "hugging_face_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2-VL-BF16",
      "name": "NVIDIA: Nemotron Nano 12B 2 VL",
      "created": 1761675565,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image+video->text",
        "input_modalities": [
          "image",
          "text",
          "video"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000002",
        "completion": "0.0000006"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "minimax/minimax-m2",
      "canonical_slug": "minimax/minimax-m2",
      "hugging_face_id": "MiniMaxAI/MiniMax-M2",
      "name": "MiniMax: MiniMax M2",
      "created": 1761252093,
      "context_length": 196608,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000000255",
        "completion": "0.000001",
        "input_cache_read": "0.00000003"
      },
      "top_provider": {
        "context_length": 196608,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-vl-32b-instruct",
      "canonical_slug": "qwen/qwen3-vl-32b-instruct",
      "hugging_face_id": "Qwen/Qwen3-VL-32B-Instruct",
      "name": "Qwen: Qwen3 VL 32B Instruct",
      "created": 1761231332,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000000104",
        "completion": "0.000000416"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "liquid/lfm2-8b-a1b",
      "canonical_slug": "liquid/lfm2-8b-a1b",
      "hugging_face_id": "LiquidAI/LFM2-8B-A1B",
      "name": "LiquidAI: LFM2-8B-A1B",
      "created": 1760970984,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000001",
        "completion": "0.00000002"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "liquid/lfm-2.2-6b",
      "canonical_slug": "liquid/lfm-2.2-6b",
      "hugging_face_id": "LiquidAI/LFM2-2.6B",
      "name": "LiquidAI: LFM2-2.6B",
      "created": 1760970889,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000001",
        "completion": "0.00000002"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "ibm-granite/granite-4.0-h-micro",
      "canonical_slug": "ibm-granite/granite-4.0-h-micro",
      "hugging_face_id": "ibm-granite/granite-4.0-h-micro",
      "name": "IBM: Granite 4.0 Micro",
      "created": 1760927695,
      "context_length": 131000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000000017",
        "completion": "0.00000011"
      },
      "top_provider": {
        "context_length": 131000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-5-image-mini",
      "canonical_slug": "openai/gpt-5-image-mini",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-5 Image Mini",
      "created": 1760624583,
      "context_length": 400000,
      "architecture": {
        "modality": "text+image+file->text+image",
        "input_modalities": [
          "file",
          "image",
          "text"
        ],
        "output_modalities": [
          "image",
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000025",
        "completion": "0.000002",
        "web_search": "0.01",
        "input_cache_read": "0.00000025"
      },
      "top_provider": {
        "context_length": 400000,
        "max_completion_tokens": 128000,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "anthropic/claude-haiku-4.5",
      "canonical_slug": "anthropic/claude-4.5-haiku-20251001",
      "hugging_face_id": "",
      "name": "Anthropic: Claude Haiku 4.5",
      "created": 1760547638,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "image",
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000001",
        "completion": "0.000005",
        "web_search": "0.01",
        "input_cache_read": "0.0000001",
        "input_cache_write": "0.00000125"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 64000,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-vl-8b-thinking",
      "canonical_slug": "qwen/qwen3-vl-8b-thinking",
      "hugging_face_id": "Qwen/Qwen3-VL-8B-Thinking",
      "name": "Qwen: Qwen3 VL 8B Thinking",
      "created": 1760463746,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "image",
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000000117",
        "completion": "0.000001365"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-vl-8b-instruct",
      "canonical_slug": "qwen/qwen3-vl-8b-instruct",
      "hugging_face_id": "Qwen/Qwen3-VL-8B-Instruct",
      "name": "Qwen: Qwen3 VL 8B Instruct",
      "created": 1760463308,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "image",
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000008",
        "completion": "0.0000005"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-5-image",
      "canonical_slug": "openai/gpt-5-image",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-5 Image",
      "created": 1760447986,
      "context_length": 400000,
      "architecture": {
        "modality": "text+image+file->text+image",
        "input_modalities": [
          "image",
          "text",
          "file"
        ],
        "output_modalities": [
          "image",
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00001",
        "completion": "0.00001",
        "web_search": "0.01",
        "input_cache_read": "0.00000125"
      },
      "top_provider": {
        "context_length": 400000,
        "max_completion_tokens": 128000,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/o3-deep-research",
      "canonical_slug": "openai/o3-deep-research-2025-06-26",
      "hugging_face_id": "",
      "name": "OpenAI: o3 Deep Research",
      "created": 1760129661,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "image",
          "text",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00001",
        "completion": "0.00004",
        "web_search": "0.01",
        "input_cache_read": "0.0000025"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 100000,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/o4-mini-deep-research",
      "canonical_slug": "openai/o4-mini-deep-research-2025-06-26",
      "hugging_face_id": "",
      "name": "OpenAI: o4 Mini Deep Research",
      "created": 1760129642,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "file",
          "image",
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000002",
        "completion": "0.000008",
        "web_search": "0.01",
        "input_cache_read": "0.0000005"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 100000,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "nvidia/llama-3.3-nemotron-super-49b-v1.5",
      "canonical_slug": "nvidia/llama-3.3-nemotron-super-49b-v1.5",
      "hugging_face_id": "nvidia/Llama-3_3-Nemotron-Super-49B-v1_5",
      "name": "NVIDIA: Llama 3.3 Nemotron Super 49B V1.5",
      "created": 1760101395,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000001",
        "completion": "0.0000004"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "baidu/ernie-4.5-21b-a3b-thinking",
      "canonical_slug": "baidu/ernie-4.5-21b-a3b-thinking",
      "hugging_face_id": "baidu/ERNIE-4.5-21B-A3B-Thinking",
      "name": "Baidu: ERNIE 4.5 21B A3B Thinking",
      "created": 1760048887,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000007",
        "completion": "0.00000028"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemini-2.5-flash-image",
      "canonical_slug": "google/gemini-2.5-flash-image",
      "hugging_face_id": "",
      "name": "Google: Gemini 2.5 Flash Image (Nano Banana)",
      "created": 1759870431,
      "context_length": 32768,
      "architecture": {
        "modality": "text+image->text+image",
        "input_modalities": [
          "image",
          "text"
        ],
        "output_modalities": [
          "image",
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000003",
        "completion": "0.0000025",
        "image": "0.0000003",
        "audio": "0.000001",
        "internal_reasoning": "0.0000025",
        "input_cache_read": "0.00000003",
        "input_cache_write": "0.00000008333333333333334"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-vl-30b-a3b-thinking",
      "canonical_slug": "qwen/qwen3-vl-30b-a3b-thinking",
      "hugging_face_id": "Qwen/Qwen3-VL-30B-A3B-Thinking",
      "name": "Qwen: Qwen3 VL 30B A3B Thinking",
      "created": 1759794479,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0",
        "request": "0",
        "image": "0",
        "web_search": "0",
        "internal_reasoning": "0"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-vl-30b-a3b-instruct",
      "canonical_slug": "qwen/qwen3-vl-30b-a3b-instruct",
      "hugging_face_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "name": "Qwen: Qwen3 VL 30B A3B Instruct",
      "created": 1759794476,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000013",
        "completion": "0.00000052"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-5-pro",
      "canonical_slug": "openai/gpt-5-pro-2025-10-06",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-5 Pro",
      "created": 1759776663,
      "context_length": 400000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "image",
          "text",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000015",
        "completion": "0.00012",
        "web_search": "0.01"
      },
      "top_provider": {
        "context_length": 400000,
        "max_completion_tokens": 128000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "z-ai/glm-4.6",
      "canonical_slug": "z-ai/glm-4.6",
      "hugging_face_id": "",
      "name": "Z.ai: GLM 4.6",
      "created": 1759235576,
      "context_length": 202752,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000035",
        "completion": "0.0000015",
        "input_cache_read": "0.000000175"
      },
      "top_provider": {
        "context_length": 202752,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "z-ai/glm-4.6:exacto",
      "canonical_slug": "z-ai/glm-4.6",
      "hugging_face_id": "",
      "name": "Z.ai: GLM 4.6 (exacto)",
      "created": 1759235576,
      "context_length": 204800,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000044",
        "completion": "0.00000176",
        "input_cache_read": "0.00000011"
      },
      "top_provider": {
        "context_length": 204800,
        "max_completion_tokens": 131072,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "anthropic/claude-sonnet-4.5",
      "canonical_slug": "anthropic/claude-4.5-sonnet-20250929",
      "hugging_face_id": "",
      "name": "Anthropic: Claude Sonnet 4.5",
      "created": 1759161676,
      "context_length": 1000000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "text",
          "image",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000003",
        "completion": "0.000015",
        "web_search": "0.01",
        "input_cache_read": "0.0000003",
        "input_cache_write": "0.00000375"
      },
      "top_provider": {
        "context_length": 1000000,
        "max_completion_tokens": 64000,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "deepseek/deepseek-v3.2-exp",
      "canonical_slug": "deepseek/deepseek-v3.2-exp",
      "hugging_face_id": "deepseek-ai/DeepSeek-V3.2-Exp",
      "name": "DeepSeek: DeepSeek V3.2 Exp",
      "created": 1759150481,
      "context_length": 163840,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "DeepSeek",
        "instruct_type": "deepseek-v3.1"
      },
      "pricing": {
        "prompt": "0.00000027",
        "completion": "0.00000041"
      },
      "top_provider": {
        "context_length": 163840,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "thedrummer/cydonia-24b-v4.1",
      "canonical_slug": "thedrummer/cydonia-24b-v4.1",
      "hugging_face_id": "thedrummer/cydonia-24b-v4.1",
      "name": "TheDrummer: Cydonia 24B V4.1",
      "created": 1758931878,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000003",
        "completion": "0.0000005"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 131072,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "relace/relace-apply-3",
      "canonical_slug": "relace/relace-apply-3",
      "hugging_face_id": "",
      "name": "Relace: Relace Apply 3",
      "created": 1758891572,
      "context_length": 256000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000085",
        "completion": "0.00000125"
      },
      "top_provider": {
        "context_length": 256000,
        "max_completion_tokens": 128000,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "seed",
        "stop"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemini-2.5-flash-preview-09-2025",
      "canonical_slug": "google/gemini-2.5-flash-preview-09-2025",
      "hugging_face_id": "",
      "name": "Google: Gemini 2.5 Flash Preview 09-2025",
      "created": 1758820178,
      "context_length": 1048576,
      "architecture": {
        "modality": "text+image+file+audio+video->text",
        "input_modalities": [
          "image",
          "file",
          "text",
          "audio",
          "video"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000003",
        "completion": "0.0000025",
        "image": "0.0000003",
        "audio": "0.000001",
        "internal_reasoning": "0.0000025",
        "input_cache_read": "0.00000003",
        "input_cache_write": "0.00000008333333333333334"
      },
      "top_provider": {
        "context_length": 1048576,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": "2026-02-17"
    },
    {
      "id": "google/gemini-2.5-flash-lite-preview-09-2025",
      "canonical_slug": "google/gemini-2.5-flash-lite-preview-09-2025",
      "hugging_face_id": "",
      "name": "Google: Gemini 2.5 Flash Lite Preview 09-2025",
      "created": 1758819686,
      "context_length": 1048576,
      "architecture": {
        "modality": "text+image+file+audio+video->text",
        "input_modalities": [
          "text",
          "image",
          "file",
          "audio",
          "video"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000001",
        "completion": "0.0000004",
        "image": "0.0000001",
        "audio": "0.0000003",
        "internal_reasoning": "0.0000004",
        "input_cache_read": "0.00000001",
        "input_cache_write": "0.00000008333333333333334"
      },
      "top_provider": {
        "context_length": 1048576,
        "max_completion_tokens": 65535,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-vl-235b-a22b-thinking",
      "canonical_slug": "qwen/qwen3-vl-235b-a22b-thinking",
      "hugging_face_id": "Qwen/Qwen3-VL-235B-A22B-Thinking",
      "name": "Qwen: Qwen3 VL 235B A22B Thinking",
      "created": 1758668690,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0",
        "request": "0",
        "image": "0",
        "web_search": "0",
        "internal_reasoning": "0"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-vl-235b-a22b-instruct",
      "canonical_slug": "qwen/qwen3-vl-235b-a22b-instruct",
      "hugging_face_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "name": "Qwen: Qwen3 VL 235B A22B Instruct",
      "created": 1758668687,
      "context_length": 262144,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000002",
        "completion": "0.00000088",
        "input_cache_read": "0.00000011"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-max",
      "canonical_slug": "qwen/qwen3-max",
      "hugging_face_id": "",
      "name": "Qwen: Qwen3 Max",
      "created": 1758662808,
      "context_length": 262144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000012",
        "completion": "0.000006",
        "input_cache_read": "0.00000024"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-coder-plus",
      "canonical_slug": "qwen/qwen3-coder-plus",
      "hugging_face_id": "",
      "name": "Qwen: Qwen3 Coder Plus",
      "created": 1758662707,
      "context_length": 1000000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000001",
        "completion": "0.000005",
        "input_cache_read": "0.0000002"
      },
      "top_provider": {
        "context_length": 1000000,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-5-codex",
      "canonical_slug": "openai/gpt-5-codex",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-5 Codex",
      "created": 1758643403,
      "context_length": 400000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000125",
        "completion": "0.00001",
        "input_cache_read": "0.000000125"
      },
      "top_provider": {
        "context_length": 400000,
        "max_completion_tokens": 128000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "deepseek/deepseek-v3.1-terminus:exacto",
      "canonical_slug": "deepseek/deepseek-v3.1-terminus",
      "hugging_face_id": "deepseek-ai/DeepSeek-V3.1-Terminus",
      "name": "DeepSeek: DeepSeek V3.1 Terminus (exacto)",
      "created": 1758548275,
      "context_length": 163840,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "DeepSeek",
        "instruct_type": "deepseek-v3.1"
      },
      "pricing": {
        "prompt": "0.00000021",
        "completion": "0.00000079",
        "input_cache_read": "0.000000168"
      },
      "top_provider": {
        "context_length": 163840,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "deepseek/deepseek-v3.1-terminus",
      "canonical_slug": "deepseek/deepseek-v3.1-terminus",
      "hugging_face_id": "deepseek-ai/DeepSeek-V3.1-Terminus",
      "name": "DeepSeek: DeepSeek V3.1 Terminus",
      "created": 1758548275,
      "context_length": 163840,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "DeepSeek",
        "instruct_type": "deepseek-v3.1"
      },
      "pricing": {
        "prompt": "0.00000021",
        "completion": "0.00000079",
        "input_cache_read": "0.0000001300000002"
      },
      "top_provider": {
        "context_length": 163840,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "x-ai/grok-4-fast",
      "canonical_slug": "x-ai/grok-4-fast",
      "hugging_face_id": "",
      "name": "xAI: Grok 4 Fast",
      "created": 1758240090,
      "context_length": 2000000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Grok",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000002",
        "completion": "0.0000005",
        "web_search": "0.005",
        "input_cache_read": "0.00000005"
      },
      "top_provider": {
        "context_length": 2000000,
        "max_completion_tokens": 30000,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "logprobs",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "alibaba/tongyi-deepresearch-30b-a3b",
      "canonical_slug": "alibaba/tongyi-deepresearch-30b-a3b",
      "hugging_face_id": "Alibaba-NLP/Tongyi-DeepResearch-30B-A3B",
      "name": "Tongyi DeepResearch 30B A3B",
      "created": 1758210804,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000009",
        "completion": "0.00000045",
        "input_cache_read": "0.00000009"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 131072,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-coder-flash",
      "canonical_slug": "qwen/qwen3-coder-flash",
      "hugging_face_id": "",
      "name": "Qwen: Qwen3 Coder Flash",
      "created": 1758115536,
      "context_length": 1000000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000003",
        "completion": "0.0000015",
        "input_cache_read": "0.00000006"
      },
      "top_provider": {
        "context_length": 1000000,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "opengvlab/internvl3-78b",
      "canonical_slug": "opengvlab/internvl3-78b",
      "hugging_face_id": "OpenGVLab/InternVL3-78B",
      "name": "OpenGVLab: InternVL3 78B",
      "created": 1757962555,
      "context_length": 32768,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "image",
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000015",
        "completion": "0.0000006",
        "input_cache_read": "0.000000075"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-next-80b-a3b-thinking",
      "canonical_slug": "qwen/qwen3-next-80b-a3b-thinking-2509",
      "hugging_face_id": "Qwen/Qwen3-Next-80B-A3B-Thinking",
      "name": "Qwen: Qwen3 Next 80B A3B Thinking",
      "created": 1757612284,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000015",
        "completion": "0.0000012"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-next-80b-a3b-instruct:free",
      "canonical_slug": "qwen/qwen3-next-80b-a3b-instruct-2509",
      "hugging_face_id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "name": "Qwen: Qwen3 Next 80B A3B Instruct (free)",
      "created": 1757612213,
      "context_length": 262144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-next-80b-a3b-instruct",
      "canonical_slug": "qwen/qwen3-next-80b-a3b-instruct-2509",
      "hugging_face_id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "name": "Qwen: Qwen3 Next 80B A3B Instruct",
      "created": 1757612213,
      "context_length": 262144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000009",
        "completion": "0.0000011"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "meituan/longcat-flash-chat",
      "canonical_slug": "meituan/longcat-flash-chat",
      "hugging_face_id": "meituan-longcat/LongCat-Flash-Chat",
      "name": "Meituan: LongCat Flash Chat",
      "created": 1757427658,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000002",
        "completion": "0.0000008",
        "input_cache_read": "0.0000002"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen-plus-2025-07-28",
      "canonical_slug": "qwen/qwen-plus-2025-07-28",
      "hugging_face_id": "",
      "name": "Qwen: Qwen Plus 0728",
      "created": 1757347599,
      "context_length": 1000000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000004",
        "completion": "0.0000012"
      },
      "top_provider": {
        "context_length": 1000000,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen-plus-2025-07-28:thinking",
      "canonical_slug": "qwen/qwen-plus-2025-07-28",
      "hugging_face_id": "",
      "name": "Qwen: Qwen Plus 0728 (thinking)",
      "created": 1757347599,
      "context_length": 1000000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000004",
        "completion": "0.0000012"
      },
      "top_provider": {
        "context_length": 1000000,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "nvidia/nemotron-nano-9b-v2:free",
      "canonical_slug": "nvidia/nemotron-nano-9b-v2",
      "hugging_face_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "name": "NVIDIA: Nemotron Nano 9B V2 (free)",
      "created": 1757106807,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "nvidia/nemotron-nano-9b-v2",
      "canonical_slug": "nvidia/nemotron-nano-9b-v2",
      "hugging_face_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "name": "NVIDIA: Nemotron Nano 9B V2",
      "created": 1757106807,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000004",
        "completion": "0.00000016"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "moonshotai/kimi-k2-0905",
      "canonical_slug": "moonshotai/kimi-k2-0905",
      "hugging_face_id": "moonshotai/Kimi-K2-Instruct-0905",
      "name": "MoonshotAI: Kimi K2 0905",
      "created": 1757021147,
      "context_length": 262144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000039",
        "completion": "0.0000019",
        "input_cache_read": "0.000000195"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": 262144,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "moonshotai/kimi-k2-0905:exacto",
      "canonical_slug": "moonshotai/kimi-k2-0905",
      "hugging_face_id": "moonshotai/Kimi-K2-Instruct-0905",
      "name": "MoonshotAI: Kimi K2 0905 (exacto)",
      "created": 1757021147,
      "context_length": 262144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000006",
        "completion": "0.0000025"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-30b-a3b-thinking-2507",
      "canonical_slug": "qwen/qwen3-30b-a3b-thinking-2507",
      "hugging_face_id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "name": "Qwen: Qwen3 30B A3B Thinking 2507",
      "created": 1756399192,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000000051",
        "completion": "0.00000034"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "x-ai/grok-code-fast-1",
      "canonical_slug": "x-ai/grok-code-fast-1",
      "hugging_face_id": "",
      "name": "xAI: Grok Code Fast 1",
      "created": 1756238927,
      "context_length": 256000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Grok",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000002",
        "completion": "0.0000015",
        "web_search": "0.005",
        "input_cache_read": "0.00000002"
      },
      "top_provider": {
        "context_length": 256000,
        "max_completion_tokens": 10000,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "logprobs",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "nousresearch/hermes-4-70b",
      "canonical_slug": "nousresearch/hermes-4-70b",
      "hugging_face_id": "NousResearch/Hermes-4-70B",
      "name": "Nous: Hermes 4 70B",
      "created": 1756236182,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000011",
        "completion": "0.00000038",
        "input_cache_read": "0.000000055"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 131072,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "nousresearch/hermes-4-405b",
      "canonical_slug": "nousresearch/hermes-4-405b",
      "hugging_face_id": "NousResearch/Hermes-4-405B",
      "name": "Nous: Hermes 4 405B",
      "created": 1756235463,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000001",
        "completion": "0.000003"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "deepseek/deepseek-chat-v3.1",
      "canonical_slug": "deepseek/deepseek-chat-v3.1",
      "hugging_face_id": "deepseek-ai/DeepSeek-V3.1",
      "name": "DeepSeek: DeepSeek V3.1",
      "created": 1755779628,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "DeepSeek",
        "instruct_type": "deepseek-v3.1"
      },
      "pricing": {
        "prompt": "0.00000015",
        "completion": "0.00000075"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 7168,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-4o-audio-preview",
      "canonical_slug": "openai/gpt-4o-audio-preview",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-4o Audio",
      "created": 1755233061,
      "context_length": 128000,
      "architecture": {
        "modality": "text+audio->text+audio",
        "input_modalities": [
          "audio",
          "text"
        ],
        "output_modalities": [
          "text",
          "audio"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000025",
        "completion": "0.00001",
        "audio": "0.00004"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mistral-medium-3.1",
      "canonical_slug": "mistralai/mistral-medium-3.1",
      "hugging_face_id": "",
      "name": "Mistral: Mistral Medium 3.1",
      "created": 1755095639,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000004",
        "completion": "0.000002"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "baidu/ernie-4.5-21b-a3b",
      "canonical_slug": "baidu/ernie-4.5-21b-a3b",
      "hugging_face_id": "baidu/ERNIE-4.5-21B-A3B-PT",
      "name": "Baidu: ERNIE 4.5 21B A3B",
      "created": 1755034167,
      "context_length": 120000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000007",
        "completion": "0.00000028"
      },
      "top_provider": {
        "context_length": 120000,
        "max_completion_tokens": 8000,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "baidu/ernie-4.5-vl-28b-a3b",
      "canonical_slug": "baidu/ernie-4.5-vl-28b-a3b",
      "hugging_face_id": "baidu/ERNIE-4.5-VL-28B-A3B-PT",
      "name": "Baidu: ERNIE 4.5 VL 28B A3B",
      "created": 1755032836,
      "context_length": 30000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000014",
        "completion": "0.00000056"
      },
      "top_provider": {
        "context_length": 30000,
        "max_completion_tokens": 8000,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "z-ai/glm-4.5v",
      "canonical_slug": "z-ai/glm-4.5v",
      "hugging_face_id": "zai-org/GLM-4.5V",
      "name": "Z.ai: GLM 4.5V",
      "created": 1754922288,
      "context_length": 65536,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000006",
        "completion": "0.0000018",
        "input_cache_read": "0.00000011"
      },
      "top_provider": {
        "context_length": 65536,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "ai21/jamba-large-1.7",
      "canonical_slug": "ai21/jamba-large-1.7",
      "hugging_face_id": "ai21labs/AI21-Jamba-Large-1.7",
      "name": "AI21: Jamba Large 1.7",
      "created": 1754669020,
      "context_length": 256000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000002",
        "completion": "0.000008"
      },
      "top_provider": {
        "context_length": 256000,
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-5-chat",
      "canonical_slug": "openai/gpt-5-chat-2025-08-07",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-5 Chat",
      "created": 1754587837,
      "context_length": 128000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "file",
          "image",
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000125",
        "completion": "0.00001",
        "web_search": "0.01",
        "input_cache_read": "0.000000125"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "structured_outputs"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-5",
      "canonical_slug": "openai/gpt-5-2025-08-07",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-5",
      "created": 1754587413,
      "context_length": 400000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "text",
          "image",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000125",
        "completion": "0.00001",
        "web_search": "0.01",
        "input_cache_read": "0.000000125"
      },
      "top_provider": {
        "context_length": 400000,
        "max_completion_tokens": 128000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-5-mini",
      "canonical_slug": "openai/gpt-5-mini-2025-08-07",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-5 Mini",
      "created": 1754587407,
      "context_length": 400000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "text",
          "image",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000025",
        "completion": "0.000002",
        "web_search": "0.01",
        "input_cache_read": "0.000000025"
      },
      "top_provider": {
        "context_length": 400000,
        "max_completion_tokens": 128000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-5-nano",
      "canonical_slug": "openai/gpt-5-nano-2025-08-07",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-5 Nano",
      "created": 1754587402,
      "context_length": 400000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "text",
          "image",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000005",
        "completion": "0.0000004",
        "web_search": "0.01",
        "input_cache_read": "0.000000005"
      },
      "top_provider": {
        "context_length": 400000,
        "max_completion_tokens": 128000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-oss-120b:free",
      "canonical_slug": "openai/gpt-oss-120b",
      "hugging_face_id": "openai/gpt-oss-120b",
      "name": "OpenAI: gpt-oss-120b (free)",
      "created": 1754414231,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 131072,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-oss-120b",
      "canonical_slug": "openai/gpt-oss-120b",
      "hugging_face_id": "openai/gpt-oss-120b",
      "name": "OpenAI: gpt-oss-120b",
      "created": 1754414231,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000000039",
        "completion": "0.00000019"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "reasoning_effort",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-oss-120b:exacto",
      "canonical_slug": "openai/gpt-oss-120b",
      "hugging_face_id": "openai/gpt-oss-120b",
      "name": "OpenAI: gpt-oss-120b (exacto)",
      "created": 1754414231,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000000039",
        "completion": "0.00000019"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-oss-20b:free",
      "canonical_slug": "openai/gpt-oss-20b",
      "hugging_face_id": "openai/gpt-oss-20b",
      "name": "OpenAI: gpt-oss-20b (free)",
      "created": 1754414229,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 131072,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-oss-20b",
      "canonical_slug": "openai/gpt-oss-20b",
      "hugging_face_id": "openai/gpt-oss-20b",
      "name": "OpenAI: gpt-oss-20b",
      "created": 1754414229,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000003",
        "completion": "0.00000014"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "reasoning_effort",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "anthropic/claude-opus-4.1",
      "canonical_slug": "anthropic/claude-4.1-opus-20250805",
      "hugging_face_id": "",
      "name": "Anthropic: Claude Opus 4.1",
      "created": 1754411591,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "image",
          "text",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000015",
        "completion": "0.000075",
        "web_search": "0.01",
        "input_cache_read": "0.0000015",
        "input_cache_write": "0.00001875"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 32000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/codestral-2508",
      "canonical_slug": "mistralai/codestral-2508",
      "hugging_face_id": "",
      "name": "Mistral: Codestral 2508",
      "created": 1754079630,
      "context_length": 256000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000003",
        "completion": "0.0000009"
      },
      "top_provider": {
        "context_length": 256000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-coder-30b-a3b-instruct",
      "canonical_slug": "qwen/qwen3-coder-30b-a3b-instruct",
      "hugging_face_id": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "name": "Qwen: Qwen3 Coder 30B A3B Instruct",
      "created": 1753972379,
      "context_length": 160000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000007",
        "completion": "0.00000027"
      },
      "top_provider": {
        "context_length": 160000,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-30b-a3b-instruct-2507",
      "canonical_slug": "qwen/qwen3-30b-a3b-instruct-2507",
      "hugging_face_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "name": "Qwen: Qwen3 30B A3B Instruct 2507",
      "created": 1753806965,
      "context_length": 262144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000008",
        "completion": "0.00000033",
        "input_cache_read": "0.00000004"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": 262144,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "z-ai/glm-4.5",
      "canonical_slug": "z-ai/glm-4.5",
      "hugging_face_id": "zai-org/GLM-4.5",
      "name": "Z.ai: GLM 4.5",
      "created": 1753471347,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000035",
        "completion": "0.00000155",
        "input_cache_read": "0.000000175"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "z-ai/glm-4.5-air:free",
      "canonical_slug": "z-ai/glm-4.5-air",
      "hugging_face_id": "zai-org/GLM-4.5-Air",
      "name": "Z.ai: GLM 4.5 Air (free)",
      "created": 1753471258,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 96000,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "z-ai/glm-4.5-air",
      "canonical_slug": "z-ai/glm-4.5-air",
      "hugging_face_id": "zai-org/GLM-4.5-Air",
      "name": "Z.ai: GLM 4.5 Air",
      "created": 1753471258,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000013",
        "completion": "0.00000085",
        "input_cache_read": "0.000000025"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 98304,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-235b-a22b-thinking-2507",
      "canonical_slug": "qwen/qwen3-235b-a22b-thinking-2507",
      "hugging_face_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "name": "Qwen: Qwen3 235B A22B Thinking 2507",
      "created": 1753449557,
      "context_length": 262144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": "qwen3"
      },
      "pricing": {
        "prompt": "0.00000011",
        "completion": "0.0000006",
        "input_cache_read": "0.000000055"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": 262144,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "z-ai/glm-4-32b",
      "canonical_slug": "z-ai/glm-4-32b-0414",
      "hugging_face_id": "",
      "name": "Z.ai: GLM 4 32B ",
      "created": 1753376617,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000001",
        "completion": "0.0000001"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-coder:free",
      "canonical_slug": "qwen/qwen3-coder-480b-a35b-07-25",
      "hugging_face_id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "name": "Qwen: Qwen3 Coder 480B A35B (free)",
      "created": 1753230546,
      "context_length": 262000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 262000,
        "max_completion_tokens": 262000,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-coder",
      "canonical_slug": "qwen/qwen3-coder-480b-a35b-07-25",
      "hugging_face_id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "name": "Qwen: Qwen3 Coder 480B A35B",
      "created": 1753230546,
      "context_length": 262144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000022",
        "completion": "0.000001",
        "input_cache_read": "0.000000022"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-coder:exacto",
      "canonical_slug": "qwen/qwen3-coder-480b-a35b-07-25",
      "hugging_face_id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "name": "Qwen: Qwen3 Coder 480B A35B (exacto)",
      "created": 1753230546,
      "context_length": 262144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000022",
        "completion": "0.0000018",
        "input_cache_read": "0.000000022"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "bytedance/ui-tars-1.5-7b",
      "canonical_slug": "bytedance/ui-tars-1.5-7b",
      "hugging_face_id": "ByteDance-Seed/UI-TARS-1.5-7B",
      "name": "ByteDance: UI-TARS 7B ",
      "created": 1753205056,
      "context_length": 128000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "image",
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000001",
        "completion": "0.0000002"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 2048,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemini-2.5-flash-lite",
      "canonical_slug": "google/gemini-2.5-flash-lite",
      "hugging_face_id": "",
      "name": "Google: Gemini 2.5 Flash Lite",
      "created": 1753200276,
      "context_length": 1048576,
      "architecture": {
        "modality": "text+image+file+audio+video->text",
        "input_modalities": [
          "text",
          "image",
          "file",
          "audio",
          "video"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000001",
        "completion": "0.0000004",
        "image": "0.0000001",
        "audio": "0.0000003",
        "internal_reasoning": "0.0000004",
        "input_cache_read": "0.00000001",
        "input_cache_write": "0.00000008333333333333334"
      },
      "top_provider": {
        "context_length": 1048576,
        "max_completion_tokens": 65535,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-235b-a22b-2507",
      "canonical_slug": "qwen/qwen3-235b-a22b-07-25",
      "hugging_face_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "name": "Qwen: Qwen3 235B A22B Instruct 2507",
      "created": 1753119555,
      "context_length": 262144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000000071",
        "completion": "0.0000001"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "reasoning_effort",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "switchpoint/router",
      "canonical_slug": "switchpoint/router",
      "hugging_face_id": "",
      "name": "Switchpoint Router",
      "created": 1752272899,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000085",
        "completion": "0.0000034"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "moonshotai/kimi-k2",
      "canonical_slug": "moonshotai/kimi-k2",
      "hugging_face_id": "moonshotai/Kimi-K2-Instruct",
      "name": "MoonshotAI: Kimi K2 0711",
      "created": 1752263252,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000005",
        "completion": "0.0000024"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/devstral-medium",
      "canonical_slug": "mistralai/devstral-medium-2507",
      "hugging_face_id": "",
      "name": "Mistral: Devstral Medium",
      "created": 1752161321,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000004",
        "completion": "0.000002"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/devstral-small",
      "canonical_slug": "mistralai/devstral-small-2507",
      "hugging_face_id": "mistralai/Devstral-Small-2507",
      "name": "Mistral: Devstral Small 1.1",
      "created": 1752160751,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000001",
        "completion": "0.0000003"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
      "canonical_slug": "venice/uncensored",
      "hugging_face_id": "cognitivecomputations/Dolphin-Mistral-24B-Venice-Edition",
      "name": "Venice: Uncensored (free)",
      "created": 1752094966,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "x-ai/grok-4",
      "canonical_slug": "x-ai/grok-4-07-09",
      "hugging_face_id": "",
      "name": "xAI: Grok 4",
      "created": 1752087689,
      "context_length": 256000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "image",
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Grok",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000003",
        "completion": "0.000015",
        "web_search": "0.005",
        "input_cache_read": "0.00000075"
      },
      "top_provider": {
        "context_length": 256000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "logprobs",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemma-3n-e2b-it:free",
      "canonical_slug": "google/gemma-3n-e2b-it",
      "hugging_face_id": "google/gemma-3n-E2B-it",
      "name": "Google: Gemma 3n 2B (free)",
      "created": 1752074904,
      "context_length": 8192,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 8192,
        "max_completion_tokens": 2048,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "tencent/hunyuan-a13b-instruct",
      "canonical_slug": "tencent/hunyuan-a13b-instruct",
      "hugging_face_id": "tencent/Hunyuan-A13B-Instruct",
      "name": "Tencent: Hunyuan A13B Instruct",
      "created": 1751987664,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000014",
        "completion": "0.00000057"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 131072,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "reasoning",
        "response_format",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "tngtech/deepseek-r1t2-chimera:free",
      "canonical_slug": "tngtech/deepseek-r1t2-chimera",
      "hugging_face_id": "tngtech/DeepSeek-TNG-R1T2-Chimera",
      "name": "TNG: DeepSeek R1T2 Chimera (free)",
      "created": 1751986985,
      "context_length": 163840,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "DeepSeek",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 163840,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "tngtech/deepseek-r1t2-chimera",
      "canonical_slug": "tngtech/deepseek-r1t2-chimera",
      "hugging_face_id": "tngtech/DeepSeek-TNG-R1T2-Chimera",
      "name": "TNG: DeepSeek R1T2 Chimera",
      "created": 1751986985,
      "context_length": 163840,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "DeepSeek",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000025",
        "completion": "0.00000085",
        "input_cache_read": "0.000000125"
      },
      "top_provider": {
        "context_length": 163840,
        "max_completion_tokens": 163840,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "morph/morph-v3-large",
      "canonical_slug": "morph/morph-v3-large",
      "hugging_face_id": "",
      "name": "Morph: Morph V3 Large",
      "created": 1751910858,
      "context_length": 262144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000009",
        "completion": "0.0000019"
      },
      "top_provider": {
        "context_length": 262144,
        "max_completion_tokens": 131072,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "stop",
        "temperature"
      ],
      "expiration_date": null
    },
    {
      "id": "morph/morph-v3-fast",
      "canonical_slug": "morph/morph-v3-fast",
      "hugging_face_id": "",
      "name": "Morph: Morph V3 Fast",
      "created": 1751910002,
      "context_length": 81920,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000008",
        "completion": "0.0000012"
      },
      "top_provider": {
        "context_length": 81920,
        "max_completion_tokens": 38000,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "stop",
        "temperature"
      ],
      "expiration_date": null
    },
    {
      "id": "baidu/ernie-4.5-vl-424b-a47b",
      "canonical_slug": "baidu/ernie-4.5-vl-424b-a47b",
      "hugging_face_id": "baidu/ERNIE-4.5-VL-424B-A47B-PT",
      "name": "Baidu: ERNIE 4.5 VL 424B A47B ",
      "created": 1751300903,
      "context_length": 123000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "image",
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000042",
        "completion": "0.00000125"
      },
      "top_provider": {
        "context_length": 123000,
        "max_completion_tokens": 16000,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "baidu/ernie-4.5-300b-a47b",
      "canonical_slug": "baidu/ernie-4.5-300b-a47b",
      "hugging_face_id": "baidu/ERNIE-4.5-300B-A47B-PT",
      "name": "Baidu: ERNIE 4.5 300B A47B ",
      "created": 1751300139,
      "context_length": 123000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000028",
        "completion": "0.0000011"
      },
      "top_provider": {
        "context_length": 123000,
        "max_completion_tokens": 12000,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "inception/mercury",
      "canonical_slug": "inception/mercury",
      "hugging_face_id": "",
      "name": "Inception: Mercury",
      "created": 1750973026,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000025",
        "completion": "0.000001"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mistral-small-3.2-24b-instruct",
      "canonical_slug": "mistralai/mistral-small-3.2-24b-instruct-2506",
      "hugging_face_id": "mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "name": "Mistral: Mistral Small 3.2 24B",
      "created": 1750443016,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "image",
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000006",
        "completion": "0.00000018",
        "input_cache_read": "0.00000003"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 131072,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "minimax/minimax-m1",
      "canonical_slug": "minimax/minimax-m1",
      "hugging_face_id": "",
      "name": "MiniMax: MiniMax M1",
      "created": 1750200414,
      "context_length": 1000000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000004",
        "completion": "0.0000022"
      },
      "top_provider": {
        "context_length": 1000000,
        "max_completion_tokens": 40000,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemini-2.5-flash",
      "canonical_slug": "google/gemini-2.5-flash",
      "hugging_face_id": "",
      "name": "Google: Gemini 2.5 Flash",
      "created": 1750172488,
      "context_length": 1048576,
      "architecture": {
        "modality": "text+image+file+audio+video->text",
        "input_modalities": [
          "file",
          "image",
          "text",
          "audio",
          "video"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000003",
        "completion": "0.0000025",
        "image": "0.0000003",
        "audio": "0.000001",
        "internal_reasoning": "0.0000025",
        "input_cache_read": "0.00000003",
        "input_cache_write": "0.00000008333333333333334"
      },
      "top_provider": {
        "context_length": 1048576,
        "max_completion_tokens": 65535,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemini-2.5-pro",
      "canonical_slug": "google/gemini-2.5-pro",
      "hugging_face_id": "",
      "name": "Google: Gemini 2.5 Pro",
      "created": 1750169544,
      "context_length": 1048576,
      "architecture": {
        "modality": "text+image+file+audio+video->text",
        "input_modalities": [
          "text",
          "image",
          "file",
          "audio",
          "video"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000125",
        "completion": "0.00001",
        "image": "0.00000125",
        "audio": "0.00000125",
        "internal_reasoning": "0.00001",
        "input_cache_read": "0.000000125",
        "input_cache_write": "0.000000375"
      },
      "top_provider": {
        "context_length": 1048576,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/o3-pro",
      "canonical_slug": "openai/o3-pro-2025-06-10",
      "hugging_face_id": "",
      "name": "OpenAI: o3 Pro",
      "created": 1749598352,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "text",
          "file",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00002",
        "completion": "0.00008",
        "web_search": "0.01"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 100000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "x-ai/grok-3-mini",
      "canonical_slug": "x-ai/grok-3-mini",
      "hugging_face_id": "",
      "name": "xAI: Grok 3 Mini",
      "created": 1749583245,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Grok",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000003",
        "completion": "0.0000005",
        "web_search": "0.005",
        "input_cache_read": "0.000000075"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "logprobs",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "x-ai/grok-3",
      "canonical_slug": "x-ai/grok-3",
      "hugging_face_id": "",
      "name": "xAI: Grok 3",
      "created": 1749582908,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Grok",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000003",
        "completion": "0.000015",
        "web_search": "0.005",
        "input_cache_read": "0.00000075"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemini-2.5-pro-preview",
      "canonical_slug": "google/gemini-2.5-pro-preview-06-05",
      "hugging_face_id": "",
      "name": "Google: Gemini 2.5 Pro Preview 06-05",
      "created": 1749137257,
      "context_length": 1048576,
      "architecture": {
        "modality": "text+image+file+audio->text",
        "input_modalities": [
          "file",
          "image",
          "text",
          "audio"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000125",
        "completion": "0.00001",
        "image": "0.00000125",
        "audio": "0.00000125",
        "internal_reasoning": "0.00001",
        "input_cache_read": "0.000000125",
        "input_cache_write": "0.000000375"
      },
      "top_provider": {
        "context_length": 1048576,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "deepseek/deepseek-r1-0528:free",
      "canonical_slug": "deepseek/deepseek-r1-0528",
      "hugging_face_id": "deepseek-ai/DeepSeek-R1-0528",
      "name": "DeepSeek: R1 0528 (free)",
      "created": 1748455170,
      "context_length": 163840,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "DeepSeek",
        "instruct_type": "deepseek-r1"
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 163840,
        "max_completion_tokens": 163840,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "deepseek/deepseek-r1-0528",
      "canonical_slug": "deepseek/deepseek-r1-0528",
      "hugging_face_id": "deepseek-ai/DeepSeek-R1-0528",
      "name": "DeepSeek: R1 0528",
      "created": 1748455170,
      "context_length": 163840,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "DeepSeek",
        "instruct_type": "deepseek-r1"
      },
      "pricing": {
        "prompt": "0.0000004",
        "completion": "0.00000175",
        "input_cache_read": "0.0000002"
      },
      "top_provider": {
        "context_length": 163840,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "anthropic/claude-opus-4",
      "canonical_slug": "anthropic/claude-4-opus-20250522",
      "hugging_face_id": "",
      "name": "Anthropic: Claude Opus 4",
      "created": 1747931245,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "image",
          "text",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000015",
        "completion": "0.000075",
        "web_search": "0.01",
        "input_cache_read": "0.0000015",
        "input_cache_write": "0.00001875"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 32000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "anthropic/claude-sonnet-4",
      "canonical_slug": "anthropic/claude-4-sonnet-20250522",
      "hugging_face_id": "",
      "name": "Anthropic: Claude Sonnet 4",
      "created": 1747930371,
      "context_length": 1000000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "image",
          "text",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000003",
        "completion": "0.000015",
        "web_search": "0.01",
        "input_cache_read": "0.0000003",
        "input_cache_write": "0.00000375"
      },
      "top_provider": {
        "context_length": 1000000,
        "max_completion_tokens": 64000,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemma-3n-e4b-it:free",
      "canonical_slug": "google/gemma-3n-e4b-it",
      "hugging_face_id": "google/gemma-3n-E4B-it",
      "name": "Google: Gemma 3n 4B (free)",
      "created": 1747776824,
      "context_length": 8192,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 8192,
        "max_completion_tokens": 2048,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemma-3n-e4b-it",
      "canonical_slug": "google/gemma-3n-e4b-it",
      "hugging_face_id": "google/gemma-3n-E4B-it",
      "name": "Google: Gemma 3n 4B",
      "created": 1747776824,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000002",
        "completion": "0.00000004"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "nousresearch/deephermes-3-mistral-24b-preview",
      "canonical_slug": "nousresearch/deephermes-3-mistral-24b-preview",
      "hugging_face_id": "NousResearch/DeepHermes-3-Mistral-24B-Preview",
      "name": "Nous: DeepHermes 3 Mistral 24B Preview",
      "created": 1746830904,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000002",
        "completion": "0.0000001",
        "input_cache_read": "0.00000001"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mistral-medium-3",
      "canonical_slug": "mistralai/mistral-medium-3",
      "hugging_face_id": "",
      "name": "Mistral: Mistral Medium 3",
      "created": 1746627341,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000004",
        "completion": "0.000002"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemini-2.5-pro-preview-05-06",
      "canonical_slug": "google/gemini-2.5-pro-preview-03-25",
      "hugging_face_id": "",
      "name": "Google: Gemini 2.5 Pro Preview 05-06",
      "created": 1746578513,
      "context_length": 1048576,
      "architecture": {
        "modality": "text+image+file+audio+video->text",
        "input_modalities": [
          "text",
          "image",
          "file",
          "audio",
          "video"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000125",
        "completion": "0.00001",
        "image": "0.00000125",
        "audio": "0.00000125",
        "internal_reasoning": "0.00001",
        "input_cache_read": "0.000000125",
        "input_cache_write": "0.000000375"
      },
      "top_provider": {
        "context_length": 1048576,
        "max_completion_tokens": 65535,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "arcee-ai/spotlight",
      "canonical_slug": "arcee-ai/spotlight",
      "hugging_face_id": "",
      "name": "Arcee AI: Spotlight",
      "created": 1746481552,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "image",
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000018",
        "completion": "0.00000018"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 65537,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "arcee-ai/maestro-reasoning",
      "canonical_slug": "arcee-ai/maestro-reasoning",
      "hugging_face_id": "",
      "name": "Arcee AI: Maestro Reasoning",
      "created": 1746481269,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000009",
        "completion": "0.0000033"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 32000,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "arcee-ai/virtuoso-large",
      "canonical_slug": "arcee-ai/virtuoso-large",
      "hugging_face_id": "",
      "name": "Arcee AI: Virtuoso Large",
      "created": 1746478885,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000075",
        "completion": "0.0000012"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 64000,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "arcee-ai/coder-large",
      "canonical_slug": "arcee-ai/coder-large",
      "hugging_face_id": "",
      "name": "Arcee AI: Coder Large",
      "created": 1746478663,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000005",
        "completion": "0.0000008"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "inception/mercury-coder",
      "canonical_slug": "inception/mercury-coder-small-beta",
      "hugging_face_id": "",
      "name": "Inception: Mercury Coder",
      "created": 1746033880,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000025",
        "completion": "0.000001"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-4b:free",
      "canonical_slug": "qwen/qwen3-4b-04-28",
      "hugging_face_id": "Qwen/Qwen3-4B",
      "name": "Qwen: Qwen3 4B (free)",
      "created": 1746031104,
      "context_length": 40960,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": "qwen3"
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 40960,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "meta-llama/llama-guard-4-12b",
      "canonical_slug": "meta-llama/llama-guard-4-12b",
      "hugging_face_id": "meta-llama/Llama-Guard-4-12B",
      "name": "Meta: Llama Guard 4 12B",
      "created": 1745975193,
      "context_length": 163840,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "image",
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000018",
        "completion": "0.00000018"
      },
      "top_provider": {
        "context_length": 163840,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-30b-a3b",
      "canonical_slug": "qwen/qwen3-30b-a3b-04-28",
      "hugging_face_id": "Qwen/Qwen3-30B-A3B",
      "name": "Qwen: Qwen3 30B A3B",
      "created": 1745878604,
      "context_length": 40960,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": "qwen3"
      },
      "pricing": {
        "prompt": "0.00000006",
        "completion": "0.00000022",
        "input_cache_read": "0.00000003"
      },
      "top_provider": {
        "context_length": 40960,
        "max_completion_tokens": 40960,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-8b",
      "canonical_slug": "qwen/qwen3-8b-04-28",
      "hugging_face_id": "Qwen/Qwen3-8B",
      "name": "Qwen: Qwen3 8B",
      "created": 1745876632,
      "context_length": 32000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": "qwen3"
      },
      "pricing": {
        "prompt": "0.00000005",
        "completion": "0.0000004",
        "input_cache_read": "0.00000005"
      },
      "top_provider": {
        "context_length": 32000,
        "max_completion_tokens": 8192,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-14b",
      "canonical_slug": "qwen/qwen3-14b-04-28",
      "hugging_face_id": "Qwen/Qwen3-14B",
      "name": "Qwen: Qwen3 14B",
      "created": 1745876478,
      "context_length": 40960,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": "qwen3"
      },
      "pricing": {
        "prompt": "0.00000005",
        "completion": "0.00000022",
        "input_cache_read": "0.000000025"
      },
      "top_provider": {
        "context_length": 40960,
        "max_completion_tokens": 40960,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-32b",
      "canonical_slug": "qwen/qwen3-32b-04-28",
      "hugging_face_id": "Qwen/Qwen3-32B",
      "name": "Qwen: Qwen3 32B",
      "created": 1745875945,
      "context_length": 40960,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": "qwen3"
      },
      "pricing": {
        "prompt": "0.00000008",
        "completion": "0.00000024",
        "input_cache_read": "0.00000004"
      },
      "top_provider": {
        "context_length": 40960,
        "max_completion_tokens": 40960,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen3-235b-a22b",
      "canonical_slug": "qwen/qwen3-235b-a22b-04-28",
      "hugging_face_id": "Qwen/Qwen3-235B-A22B",
      "name": "Qwen: Qwen3 235B A22B",
      "created": 1745875757,
      "context_length": 40960,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen3",
        "instruct_type": "qwen3"
      },
      "pricing": {
        "prompt": "0.0000003",
        "completion": "0.0000012",
        "input_cache_read": "0.00000015"
      },
      "top_provider": {
        "context_length": 40960,
        "max_completion_tokens": 40960,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "tngtech/deepseek-r1t-chimera:free",
      "canonical_slug": "tngtech/deepseek-r1t-chimera",
      "hugging_face_id": "tngtech/DeepSeek-R1T-Chimera",
      "name": "TNG: DeepSeek R1T Chimera (free)",
      "created": 1745760875,
      "context_length": 163840,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "DeepSeek",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 163840,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "tngtech/deepseek-r1t-chimera",
      "canonical_slug": "tngtech/deepseek-r1t-chimera",
      "hugging_face_id": "tngtech/DeepSeek-R1T-Chimera",
      "name": "TNG: DeepSeek R1T Chimera",
      "created": 1745760875,
      "context_length": 163840,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "DeepSeek",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000003",
        "completion": "0.0000012",
        "input_cache_read": "0.00000015"
      },
      "top_provider": {
        "context_length": 163840,
        "max_completion_tokens": 163840,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/o4-mini-high",
      "canonical_slug": "openai/o4-mini-high-2025-04-16",
      "hugging_face_id": "",
      "name": "OpenAI: o4 Mini High",
      "created": 1744824212,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "image",
          "text",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000011",
        "completion": "0.0000044",
        "web_search": "0.01",
        "input_cache_read": "0.000000275"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 100000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/o3",
      "canonical_slug": "openai/o3-2025-04-16",
      "hugging_face_id": "",
      "name": "OpenAI: o3",
      "created": 1744823457,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "image",
          "text",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000002",
        "completion": "0.000008",
        "web_search": "0.01",
        "input_cache_read": "0.0000005"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 100000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/o4-mini",
      "canonical_slug": "openai/o4-mini-2025-04-16",
      "hugging_face_id": "",
      "name": "OpenAI: o4 Mini",
      "created": 1744820942,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "image",
          "text",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000011",
        "completion": "0.0000044",
        "web_search": "0.01",
        "input_cache_read": "0.000000275"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 100000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen2.5-coder-7b-instruct",
      "canonical_slug": "qwen/qwen2.5-coder-7b-instruct",
      "hugging_face_id": "Qwen/Qwen2.5-Coder-7B-Instruct",
      "name": "Qwen: Qwen2.5 Coder 7B Instruct",
      "created": 1744734887,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000003",
        "completion": "0.00000009"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-4.1",
      "canonical_slug": "openai/gpt-4.1-2025-04-14",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-4.1",
      "created": 1744651385,
      "context_length": 1047576,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "image",
          "text",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000002",
        "completion": "0.000008",
        "web_search": "0.01",
        "input_cache_read": "0.0000005"
      },
      "top_provider": {
        "context_length": 1047576,
        "max_completion_tokens": 32768,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-4.1-mini",
      "canonical_slug": "openai/gpt-4.1-mini-2025-04-14",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-4.1 Mini",
      "created": 1744651381,
      "context_length": 1047576,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "image",
          "text",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000004",
        "completion": "0.0000016",
        "web_search": "0.01",
        "input_cache_read": "0.0000001"
      },
      "top_provider": {
        "context_length": 1047576,
        "max_completion_tokens": 32768,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-4.1-nano",
      "canonical_slug": "openai/gpt-4.1-nano-2025-04-14",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-4.1 Nano",
      "created": 1744651369,
      "context_length": 1047576,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "image",
          "text",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000001",
        "completion": "0.0000004",
        "web_search": "0.01",
        "input_cache_read": "0.000000025"
      },
      "top_provider": {
        "context_length": 1047576,
        "max_completion_tokens": 32768,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "eleutherai/llemma_7b",
      "canonical_slug": "eleutherai/llemma_7b",
      "hugging_face_id": "EleutherAI/llemma_7b",
      "name": "EleutherAI: Llemma 7b",
      "created": 1744643225,
      "context_length": 4096,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": "code-llama"
      },
      "pricing": {
        "prompt": "0.0000008",
        "completion": "0.0000012"
      },
      "top_provider": {
        "context_length": 4096,
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "alfredpros/codellama-7b-instruct-solidity",
      "canonical_slug": "alfredpros/codellama-7b-instruct-solidity",
      "hugging_face_id": "AlfredPros/CodeLlama-7b-Instruct-Solidity",
      "name": "AlfredPros: CodeLLaMa 7B Instruct Solidity",
      "created": 1744641874,
      "context_length": 4096,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": "alpaca"
      },
      "pricing": {
        "prompt": "0.0000008",
        "completion": "0.0000012"
      },
      "top_provider": {
        "context_length": 4096,
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "x-ai/grok-3-mini-beta",
      "canonical_slug": "x-ai/grok-3-mini-beta",
      "hugging_face_id": "",
      "name": "xAI: Grok 3 Mini Beta",
      "created": 1744240195,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Grok",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000003",
        "completion": "0.0000005",
        "web_search": "0.005",
        "input_cache_read": "0.000000075"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "logprobs",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "x-ai/grok-3-beta",
      "canonical_slug": "x-ai/grok-3-beta",
      "hugging_face_id": "",
      "name": "xAI: Grok 3 Beta",
      "created": 1744240068,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Grok",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000003",
        "completion": "0.000015",
        "web_search": "0.005",
        "input_cache_read": "0.00000075"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "nvidia/llama-3.1-nemotron-ultra-253b-v1",
      "canonical_slug": "nvidia/llama-3.1-nemotron-ultra-253b-v1",
      "hugging_face_id": "nvidia/Llama-3_1-Nemotron-Ultra-253B-v1",
      "name": "NVIDIA: Llama 3.1 Nemotron Ultra 253B v1",
      "created": 1744115059,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000006",
        "completion": "0.0000018"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "meta-llama/llama-4-maverick",
      "canonical_slug": "meta-llama/llama-4-maverick-17b-128e-instruct",
      "hugging_face_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
      "name": "Meta: Llama 4 Maverick",
      "created": 1743881822,
      "context_length": 1048576,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama4",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000015",
        "completion": "0.0000006"
      },
      "top_provider": {
        "context_length": 1048576,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "meta-llama/llama-4-scout",
      "canonical_slug": "meta-llama/llama-4-scout-17b-16e-instruct",
      "hugging_face_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "name": "Meta: Llama 4 Scout",
      "created": 1743881519,
      "context_length": 327680,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama4",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000008",
        "completion": "0.0000003"
      },
      "top_provider": {
        "context_length": 327680,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen2.5-vl-32b-instruct",
      "canonical_slug": "qwen/qwen2.5-vl-32b-instruct",
      "hugging_face_id": "Qwen/Qwen2.5-VL-32B-Instruct",
      "name": "Qwen: Qwen2.5 VL 32B Instruct",
      "created": 1742839838,
      "context_length": 16384,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000005",
        "completion": "0.00000022",
        "input_cache_read": "0.000000025"
      },
      "top_provider": {
        "context_length": 16384,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "deepseek/deepseek-chat-v3-0324",
      "canonical_slug": "deepseek/deepseek-chat-v3-0324",
      "hugging_face_id": "deepseek-ai/DeepSeek-V3-0324",
      "name": "DeepSeek: DeepSeek V3 0324",
      "created": 1742824755,
      "context_length": 163840,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "DeepSeek",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000019",
        "completion": "0.00000087",
        "input_cache_read": "0.000000095"
      },
      "top_provider": {
        "context_length": 163840,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/o1-pro",
      "canonical_slug": "openai/o1-pro",
      "hugging_face_id": "",
      "name": "OpenAI: o1-pro",
      "created": 1742423211,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "text",
          "image",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00015",
        "completion": "0.0006"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 100000,
        "is_moderated": true
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mistral-small-3.1-24b-instruct:free",
      "canonical_slug": "mistralai/mistral-small-3.1-24b-instruct-2503",
      "hugging_face_id": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
      "name": "Mistral: Mistral Small 3.1 24B (free)",
      "created": 1742238937,
      "context_length": 128000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mistral-small-3.1-24b-instruct",
      "canonical_slug": "mistralai/mistral-small-3.1-24b-instruct-2503",
      "hugging_face_id": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
      "name": "Mistral: Mistral Small 3.1 24B",
      "created": 1742238937,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000003",
        "completion": "0.00000011",
        "input_cache_read": "0.000000015"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 131072,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "allenai/olmo-2-0325-32b-instruct",
      "canonical_slug": "allenai/olmo-2-0325-32b-instruct",
      "hugging_face_id": "allenai/OLMo-2-0325-32B-Instruct",
      "name": "AllenAI: Olmo 2 32B Instruct",
      "created": 1741988556,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000005",
        "completion": "0.0000002"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [],
      "expiration_date": null
    },
    {
      "id": "google/gemma-3-4b-it:free",
      "canonical_slug": "google/gemma-3-4b-it",
      "hugging_face_id": "google/gemma-3-4b-it",
      "name": "Google: Gemma 3 4B (free)",
      "created": 1741905510,
      "context_length": 32768,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": "gemma"
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 8192,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemma-3-4b-it",
      "canonical_slug": "google/gemma-3-4b-it",
      "hugging_face_id": "google/gemma-3-4b-it",
      "name": "Google: Gemma 3 4B",
      "created": 1741905510,
      "context_length": 96000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": "gemma"
      },
      "pricing": {
        "prompt": "0.00000001703012",
        "completion": "0.0000000681536"
      },
      "top_provider": {
        "context_length": 96000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemma-3-12b-it:free",
      "canonical_slug": "google/gemma-3-12b-it",
      "hugging_face_id": "google/gemma-3-12b-it",
      "name": "Google: Gemma 3 12B (free)",
      "created": 1741902625,
      "context_length": 32768,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": "gemma"
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 8192,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "seed",
        "stop",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemma-3-12b-it",
      "canonical_slug": "google/gemma-3-12b-it",
      "hugging_face_id": "google/gemma-3-12b-it",
      "name": "Google: Gemma 3 12B",
      "created": 1741902625,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": "gemma"
      },
      "pricing": {
        "prompt": "0.00000003",
        "completion": "0.0000001",
        "input_cache_read": "0.000000015"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 131072,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "cohere/command-a",
      "canonical_slug": "cohere/command-a-03-2025",
      "hugging_face_id": "CohereForAI/c4ai-command-a-03-2025",
      "name": "Cohere: Command A",
      "created": 1741894342,
      "context_length": 256000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000025",
        "completion": "0.00001"
      },
      "top_provider": {
        "context_length": 256000,
        "max_completion_tokens": 8192,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-4o-mini-search-preview",
      "canonical_slug": "openai/gpt-4o-mini-search-preview-2025-03-11",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-4o-mini Search Preview",
      "created": 1741818122,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000015",
        "completion": "0.0000006",
        "web_search": "0.0275"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "structured_outputs",
        "web_search_options"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-4o-search-preview",
      "canonical_slug": "openai/gpt-4o-search-preview-2025-03-11",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-4o Search Preview",
      "created": 1741817949,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000025",
        "completion": "0.00001",
        "web_search": "0.035"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "structured_outputs",
        "web_search_options"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemma-3-27b-it:free",
      "canonical_slug": "google/gemma-3-27b-it",
      "hugging_face_id": "google/gemma-3-27b-it",
      "name": "Google: Gemma 3 27B (free)",
      "created": 1741756359,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": "gemma"
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 8192,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemma-3-27b-it",
      "canonical_slug": "google/gemma-3-27b-it",
      "hugging_face_id": "google/gemma-3-27b-it",
      "name": "Google: Gemma 3 27B",
      "created": 1741756359,
      "context_length": 128000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": "gemma"
      },
      "pricing": {
        "prompt": "0.00000004",
        "completion": "0.00000015",
        "input_cache_read": "0.00000002"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "thedrummer/skyfall-36b-v2",
      "canonical_slug": "thedrummer/skyfall-36b-v2",
      "hugging_face_id": "TheDrummer/Skyfall-36B-v2",
      "name": "TheDrummer: Skyfall 36B V2",
      "created": 1741636566,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000055",
        "completion": "0.0000008"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "perplexity/sonar-reasoning-pro",
      "canonical_slug": "perplexity/sonar-reasoning-pro",
      "hugging_face_id": "",
      "name": "Perplexity: Sonar Reasoning Pro",
      "created": 1741313308,
      "context_length": 128000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": "deepseek-r1"
      },
      "pricing": {
        "prompt": "0.000002",
        "completion": "0.000008",
        "web_search": "0.005"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "temperature",
        "top_k",
        "top_p",
        "web_search_options"
      ],
      "expiration_date": null
    },
    {
      "id": "perplexity/sonar-pro",
      "canonical_slug": "perplexity/sonar-pro",
      "hugging_face_id": "",
      "name": "Perplexity: Sonar Pro",
      "created": 1741312423,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000003",
        "completion": "0.000015",
        "web_search": "0.005"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 8000,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p",
        "web_search_options"
      ],
      "expiration_date": null
    },
    {
      "id": "perplexity/sonar-deep-research",
      "canonical_slug": "perplexity/sonar-deep-research",
      "hugging_face_id": "",
      "name": "Perplexity: Sonar Deep Research",
      "created": 1741311246,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": "deepseek-r1"
      },
      "pricing": {
        "prompt": "0.000002",
        "completion": "0.000008",
        "web_search": "0.005",
        "internal_reasoning": "0.000003"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "temperature",
        "top_k",
        "top_p",
        "web_search_options"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwq-32b",
      "canonical_slug": "qwen/qwq-32b",
      "hugging_face_id": "Qwen/QwQ-32B",
      "name": "Qwen: QwQ 32B",
      "created": 1741208814,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": "qwq"
      },
      "pricing": {
        "prompt": "0.00000015",
        "completion": "0.0000004"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemini-2.0-flash-lite-001",
      "canonical_slug": "google/gemini-2.0-flash-lite-001",
      "hugging_face_id": "",
      "name": "Google: Gemini 2.0 Flash Lite",
      "created": 1740506212,
      "context_length": 1048576,
      "architecture": {
        "modality": "text+image+file+audio+video->text",
        "input_modalities": [
          "text",
          "image",
          "file",
          "audio",
          "video"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000000075",
        "completion": "0.0000003",
        "image": "0.000000075",
        "audio": "0.000000075",
        "internal_reasoning": "0.0000003"
      },
      "top_provider": {
        "context_length": 1048576,
        "max_completion_tokens": 8192,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": "2026-03-03"
    },
    {
      "id": "anthropic/claude-3.7-sonnet:thinking",
      "canonical_slug": "anthropic/claude-3-7-sonnet-20250219",
      "hugging_face_id": "",
      "name": "Anthropic: Claude 3.7 Sonnet (thinking)",
      "created": 1740422110,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "text",
          "image",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000003",
        "completion": "0.000015",
        "web_search": "0.01",
        "input_cache_read": "0.0000003",
        "input_cache_write": "0.00000375"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 64000,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "anthropic/claude-3.7-sonnet",
      "canonical_slug": "anthropic/claude-3-7-sonnet-20250219",
      "hugging_face_id": "",
      "name": "Anthropic: Claude 3.7 Sonnet",
      "created": 1740422110,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "text",
          "image",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000003",
        "completion": "0.000015",
        "web_search": "0.01",
        "input_cache_read": "0.0000003",
        "input_cache_write": "0.00000375"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 64000,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mistral-saba",
      "canonical_slug": "mistralai/mistral-saba-2502",
      "hugging_face_id": "",
      "name": "Mistral: Saba",
      "created": 1739803239,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000002",
        "completion": "0.0000006"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "meta-llama/llama-guard-3-8b",
      "canonical_slug": "meta-llama/llama-guard-3-8b",
      "hugging_face_id": "meta-llama/Llama-Guard-3-8B",
      "name": "Llama Guard 3 8B",
      "created": 1739401318,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "none"
      },
      "pricing": {
        "prompt": "0.00000002",
        "completion": "0.00000006"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/o3-mini-high",
      "canonical_slug": "openai/o3-mini-high-2025-01-31",
      "hugging_face_id": "",
      "name": "OpenAI: o3 Mini High",
      "created": 1739372611,
      "context_length": 200000,
      "architecture": {
        "modality": "text+file->text",
        "input_modalities": [
          "text",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000011",
        "completion": "0.0000044",
        "input_cache_read": "0.00000055"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 100000,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemini-2.0-flash-001",
      "canonical_slug": "google/gemini-2.0-flash-001",
      "hugging_face_id": "",
      "name": "Google: Gemini 2.0 Flash",
      "created": 1738769413,
      "context_length": 1048576,
      "architecture": {
        "modality": "text+image+file+audio+video->text",
        "input_modalities": [
          "text",
          "image",
          "file",
          "audio",
          "video"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000001",
        "completion": "0.0000004",
        "image": "0.0000001",
        "audio": "0.0000007",
        "internal_reasoning": "0.0000004",
        "input_cache_read": "0.000000025",
        "input_cache_write": "0.00000008333333333333334"
      },
      "top_provider": {
        "context_length": 1048576,
        "max_completion_tokens": 8192,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": "2026-03-31"
    },
    {
      "id": "qwen/qwen-vl-plus",
      "canonical_slug": "qwen/qwen-vl-plus",
      "hugging_face_id": "",
      "name": "Qwen: Qwen VL Plus",
      "created": 1738731255,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000021",
        "completion": "0.00000063",
        "input_cache_read": "0.000000042"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 8192,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "aion-labs/aion-1.0",
      "canonical_slug": "aion-labs/aion-1.0",
      "hugging_face_id": "",
      "name": "AionLabs: Aion-1.0",
      "created": 1738697557,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000004",
        "completion": "0.000008"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "aion-labs/aion-1.0-mini",
      "canonical_slug": "aion-labs/aion-1.0-mini",
      "hugging_face_id": "FuseAI/FuseO1-DeepSeekR1-QwQ-SkyT1-32B-Preview",
      "name": "AionLabs: Aion-1.0-Mini",
      "created": 1738697107,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000007",
        "completion": "0.0000014"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "aion-labs/aion-rp-llama-3.1-8b",
      "canonical_slug": "aion-labs/aion-rp-llama-3.1-8b",
      "hugging_face_id": "",
      "name": "AionLabs: Aion-RP 1.0 (8B)",
      "created": 1738696718,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000008",
        "completion": "0.0000016"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen-vl-max",
      "canonical_slug": "qwen/qwen-vl-max-2025-01-25",
      "hugging_face_id": "",
      "name": "Qwen: Qwen VL Max",
      "created": 1738434304,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000008",
        "completion": "0.0000032"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen-turbo",
      "canonical_slug": "qwen/qwen-turbo-2024-11-01",
      "hugging_face_id": "",
      "name": "Qwen: Qwen-Turbo",
      "created": 1738410974,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000005",
        "completion": "0.0000002",
        "input_cache_read": "0.00000001"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 8192,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen2.5-vl-72b-instruct",
      "canonical_slug": "qwen/qwen2.5-vl-72b-instruct",
      "hugging_face_id": "Qwen/Qwen2.5-VL-72B-Instruct",
      "name": "Qwen: Qwen2.5 VL 72B Instruct",
      "created": 1738410311,
      "context_length": 32768,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000015",
        "completion": "0.0000006",
        "input_cache_read": "0.000000075"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": "2026-02-16"
    },
    {
      "id": "qwen/qwen-plus",
      "canonical_slug": "qwen/qwen-plus-2025-01-25",
      "hugging_face_id": "",
      "name": "Qwen: Qwen-Plus",
      "created": 1738409840,
      "context_length": 1000000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000004",
        "completion": "0.0000012",
        "input_cache_read": "0.00000008"
      },
      "top_provider": {
        "context_length": 1000000,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen-max",
      "canonical_slug": "qwen/qwen-max-2025-01-25",
      "hugging_face_id": "",
      "name": "Qwen: Qwen-Max ",
      "created": 1738402289,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000016",
        "completion": "0.0000064",
        "input_cache_read": "0.00000032"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 8192,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/o3-mini",
      "canonical_slug": "openai/o3-mini-2025-01-31",
      "hugging_face_id": "",
      "name": "OpenAI: o3 Mini",
      "created": 1738351721,
      "context_length": 200000,
      "architecture": {
        "modality": "text+file->text",
        "input_modalities": [
          "text",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000011",
        "completion": "0.0000044",
        "input_cache_read": "0.00000055"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 100000,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mistral-small-24b-instruct-2501",
      "canonical_slug": "mistralai/mistral-small-24b-instruct-2501",
      "hugging_face_id": "mistralai/Mistral-Small-24B-Instruct-2501",
      "name": "Mistral: Mistral Small 3",
      "created": 1738255409,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000005",
        "completion": "0.00000008"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "deepseek/deepseek-r1-distill-qwen-32b",
      "canonical_slug": "deepseek/deepseek-r1-distill-qwen-32b",
      "hugging_face_id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "name": "DeepSeek: R1 Distill Qwen 32B",
      "created": 1738194830,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": "deepseek-r1"
      },
      "pricing": {
        "prompt": "0.00000029",
        "completion": "0.00000029"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "perplexity/sonar",
      "canonical_slug": "perplexity/sonar",
      "hugging_face_id": "",
      "name": "Perplexity: Sonar",
      "created": 1738013808,
      "context_length": 127072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000001",
        "completion": "0.000001",
        "web_search": "0.005"
      },
      "top_provider": {
        "context_length": 127072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p",
        "web_search_options"
      ],
      "expiration_date": null
    },
    {
      "id": "deepseek/deepseek-r1-distill-llama-70b",
      "canonical_slug": "deepseek/deepseek-r1-distill-llama-70b",
      "hugging_face_id": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "name": "DeepSeek: R1 Distill Llama 70B",
      "created": 1737663169,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "deepseek-r1"
      },
      "pricing": {
        "prompt": "0.00000003",
        "completion": "0.00000011",
        "input_cache_read": "0.000000015"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 131072,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "deepseek/deepseek-r1",
      "canonical_slug": "deepseek/deepseek-r1",
      "hugging_face_id": "deepseek-ai/DeepSeek-R1",
      "name": "DeepSeek: R1",
      "created": 1737381095,
      "context_length": 64000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "DeepSeek",
        "instruct_type": "deepseek-r1"
      },
      "pricing": {
        "prompt": "0.0000007",
        "completion": "0.0000025"
      },
      "top_provider": {
        "context_length": 64000,
        "max_completion_tokens": 16000,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "minimax/minimax-01",
      "canonical_slug": "minimax/minimax-01",
      "hugging_face_id": "MiniMaxAI/MiniMax-Text-01",
      "name": "MiniMax: MiniMax-01",
      "created": 1736915462,
      "context_length": 1000192,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000002",
        "completion": "0.0000011"
      },
      "top_provider": {
        "context_length": 1000192,
        "max_completion_tokens": 1000192,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "microsoft/phi-4",
      "canonical_slug": "microsoft/phi-4",
      "hugging_face_id": "microsoft/phi-4",
      "name": "Microsoft: Phi 4",
      "created": 1736489872,
      "context_length": 16384,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000006",
        "completion": "0.00000014"
      },
      "top_provider": {
        "context_length": 16384,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "sao10k/l3.1-70b-hanami-x1",
      "canonical_slug": "sao10k/l3.1-70b-hanami-x1",
      "hugging_face_id": "Sao10K/L3.1-70B-Hanami-x1",
      "name": "Sao10K: Llama 3.1 70B Hanami x1",
      "created": 1736302854,
      "context_length": 16000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000003",
        "completion": "0.000003"
      },
      "top_provider": {
        "context_length": 16000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "deepseek/deepseek-chat",
      "canonical_slug": "deepseek/deepseek-chat-v3",
      "hugging_face_id": "deepseek-ai/DeepSeek-V3",
      "name": "DeepSeek: DeepSeek V3",
      "created": 1735241320,
      "context_length": 163840,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "DeepSeek",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000003",
        "completion": "0.0000012",
        "input_cache_read": "0.00000015"
      },
      "top_provider": {
        "context_length": 163840,
        "max_completion_tokens": 163840,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "sao10k/l3.3-euryale-70b",
      "canonical_slug": "sao10k/l3.3-euryale-70b-v2.3",
      "hugging_face_id": "Sao10K/L3.3-70B-Euryale-v2.3",
      "name": "Sao10K: Llama 3.3 Euryale 70B",
      "created": 1734535928,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0.00000065",
        "completion": "0.00000075"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/o1",
      "canonical_slug": "openai/o1-2024-12-17",
      "hugging_face_id": "",
      "name": "OpenAI: o1",
      "created": 1734459999,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "text",
          "image",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000015",
        "completion": "0.00006",
        "input_cache_read": "0.0000075"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 100000,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools"
      ],
      "expiration_date": null
    },
    {
      "id": "cohere/command-r7b-12-2024",
      "canonical_slug": "cohere/command-r7b-12-2024",
      "hugging_face_id": "",
      "name": "Cohere: Command R7B (12-2024)",
      "created": 1734158152,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Cohere",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000000375",
        "completion": "0.00000015"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 4000,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "meta-llama/llama-3.3-70b-instruct:free",
      "canonical_slug": "meta-llama/llama-3.3-70b-instruct",
      "hugging_face_id": "meta-llama/Llama-3.3-70B-Instruct",
      "name": "Meta: Llama 3.3 70B Instruct (free)",
      "created": 1733506137,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 128000,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "meta-llama/llama-3.3-70b-instruct",
      "canonical_slug": "meta-llama/llama-3.3-70b-instruct",
      "hugging_face_id": "meta-llama/Llama-3.3-70B-Instruct",
      "name": "Meta: Llama 3.3 70B Instruct",
      "created": 1733506137,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0.0000001",
        "completion": "0.00000032"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "amazon/nova-lite-v1",
      "canonical_slug": "amazon/nova-lite-v1",
      "hugging_face_id": "",
      "name": "Amazon: Nova Lite 1.0",
      "created": 1733437363,
      "context_length": 300000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Nova",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000006",
        "completion": "0.00000024"
      },
      "top_provider": {
        "context_length": 300000,
        "max_completion_tokens": 5120,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "amazon/nova-micro-v1",
      "canonical_slug": "amazon/nova-micro-v1",
      "hugging_face_id": "",
      "name": "Amazon: Nova Micro 1.0",
      "created": 1733437237,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Nova",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000000035",
        "completion": "0.00000014"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 5120,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "amazon/nova-pro-v1",
      "canonical_slug": "amazon/nova-pro-v1",
      "hugging_face_id": "",
      "name": "Amazon: Nova Pro 1.0",
      "created": 1733436303,
      "context_length": 300000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Nova",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000008",
        "completion": "0.0000032"
      },
      "top_provider": {
        "context_length": 300000,
        "max_completion_tokens": 5120,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-4o-2024-11-20",
      "canonical_slug": "openai/gpt-4o-2024-11-20",
      "hugging_face_id": "",
      "name": "OpenAI: GPT-4o (2024-11-20)",
      "created": 1732127594,
      "context_length": 128000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "text",
          "image",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000025",
        "completion": "0.00001",
        "input_cache_read": "0.00000125"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
        "web_search_options"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mistral-large-2411",
      "canonical_slug": "mistralai/mistral-large-2411",
      "hugging_face_id": "",
      "name": "Mistral Large 2411",
      "created": 1731978685,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000002",
        "completion": "0.000006"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mistral-large-2407",
      "canonical_slug": "mistralai/mistral-large-2407",
      "hugging_face_id": "",
      "name": "Mistral Large 2407",
      "created": 1731978415,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000002",
        "completion": "0.000006"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/pixtral-large-2411",
      "canonical_slug": "mistralai/pixtral-large-2411",
      "hugging_face_id": "",
      "name": "Mistral: Pixtral Large 2411",
      "created": 1731977388,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000002",
        "completion": "0.000006"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen-2.5-coder-32b-instruct",
      "canonical_slug": "qwen/qwen-2.5-coder-32b-instruct",
      "hugging_face_id": "Qwen/Qwen2.5-Coder-32B-Instruct",
      "name": "Qwen2.5 Coder 32B Instruct",
      "created": 1731368400,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": "chatml"
      },
      "pricing": {
        "prompt": "0.00000003",
        "completion": "0.00000011",
        "input_cache_read": "0.000000015"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "raifle/sorcererlm-8x22b",
      "canonical_slug": "raifle/sorcererlm-8x22b",
      "hugging_face_id": "rAIfle/SorcererLM-8x22b-bf16",
      "name": "SorcererLM 8x22B",
      "created": 1731105083,
      "context_length": 16000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": "vicuna"
      },
      "pricing": {
        "prompt": "0.0000045",
        "completion": "0.0000045"
      },
      "top_provider": {
        "context_length": 16000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "thedrummer/unslopnemo-12b",
      "canonical_slug": "thedrummer/unslopnemo-12b",
      "hugging_face_id": "TheDrummer/UnslopNemo-12B-v4.1",
      "name": "TheDrummer: UnslopNemo 12B",
      "created": 1731103448,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": "mistral"
      },
      "pricing": {
        "prompt": "0.0000004",
        "completion": "0.0000004"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "anthropic/claude-3.5-haiku",
      "canonical_slug": "anthropic/claude-3-5-haiku",
      "hugging_face_id": null,
      "name": "Anthropic: Claude 3.5 Haiku",
      "created": 1730678400,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000008",
        "completion": "0.000004",
        "web_search": "0.01",
        "input_cache_read": "0.00000008",
        "input_cache_write": "0.000001"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 8192,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "anthracite-org/magnum-v4-72b",
      "canonical_slug": "anthracite-org/magnum-v4-72b",
      "hugging_face_id": "anthracite-org/magnum-v4-72b",
      "name": "Magnum v4 72B",
      "created": 1729555200,
      "context_length": 16384,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": "chatml"
      },
      "pricing": {
        "prompt": "0.000003",
        "completion": "0.000005"
      },
      "top_provider": {
        "context_length": 16384,
        "max_completion_tokens": 2048,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_a",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "anthropic/claude-3.5-sonnet",
      "canonical_slug": "anthropic/claude-3.5-sonnet",
      "hugging_face_id": null,
      "name": "Anthropic: Claude 3.5 Sonnet",
      "created": 1729555200,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "text",
          "image",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000006",
        "completion": "0.00003"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 8192,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen-2.5-7b-instruct",
      "canonical_slug": "qwen/qwen-2.5-7b-instruct",
      "hugging_face_id": "Qwen/Qwen2.5-7B-Instruct",
      "name": "Qwen: Qwen2.5 7B Instruct",
      "created": 1729036800,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": "chatml"
      },
      "pricing": {
        "prompt": "0.00000004",
        "completion": "0.0000001"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "nvidia/llama-3.1-nemotron-70b-instruct",
      "canonical_slug": "nvidia/llama-3.1-nemotron-70b-instruct",
      "hugging_face_id": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
      "name": "NVIDIA: Llama 3.1 Nemotron 70B Instruct",
      "created": 1728950400,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0.0000012",
        "completion": "0.0000012"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "inflection/inflection-3-pi",
      "canonical_slug": "inflection/inflection-3-pi",
      "hugging_face_id": null,
      "name": "Inflection: Inflection 3 Pi",
      "created": 1728604800,
      "context_length": 8000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000025",
        "completion": "0.00001"
      },
      "top_provider": {
        "context_length": 8000,
        "max_completion_tokens": 1024,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "inflection/inflection-3-productivity",
      "canonical_slug": "inflection/inflection-3-productivity",
      "hugging_face_id": null,
      "name": "Inflection: Inflection 3 Productivity",
      "created": 1728604800,
      "context_length": 8000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000025",
        "completion": "0.00001"
      },
      "top_provider": {
        "context_length": 8000,
        "max_completion_tokens": 1024,
        "is_moderated": false
      },
      "supported_parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "thedrummer/rocinante-12b",
      "canonical_slug": "thedrummer/rocinante-12b",
      "hugging_face_id": "TheDrummer/Rocinante-12B-v1.1",
      "name": "TheDrummer: Rocinante 12B",
      "created": 1727654400,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": "chatml"
      },
      "pricing": {
        "prompt": "0.00000017",
        "completion": "0.00000043"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "meta-llama/llama-3.2-3b-instruct:free",
      "canonical_slug": "meta-llama/llama-3.2-3b-instruct",
      "hugging_face_id": "meta-llama/Llama-3.2-3B-Instruct",
      "name": "Meta: Llama 3.2 3B Instruct (free)",
      "created": 1727222400,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "meta-llama/llama-3.2-3b-instruct",
      "canonical_slug": "meta-llama/llama-3.2-3b-instruct",
      "hugging_face_id": "meta-llama/Llama-3.2-3B-Instruct",
      "name": "Meta: Llama 3.2 3B Instruct",
      "created": 1727222400,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0.00000002",
        "completion": "0.00000002"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "meta-llama/llama-3.2-1b-instruct",
      "canonical_slug": "meta-llama/llama-3.2-1b-instruct",
      "hugging_face_id": "meta-llama/Llama-3.2-1B-Instruct",
      "name": "Meta: Llama 3.2 1B Instruct",
      "created": 1727222400,
      "context_length": 60000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0.000000027",
        "completion": "0.0000002"
      },
      "top_provider": {
        "context_length": 60000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "meta-llama/llama-3.2-11b-vision-instruct",
      "canonical_slug": "meta-llama/llama-3.2-11b-vision-instruct",
      "hugging_face_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
      "name": "Meta: Llama 3.2 11B Vision Instruct",
      "created": 1727222400,
      "context_length": 131072,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0.000000049",
        "completion": "0.000000049"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen-2.5-72b-instruct",
      "canonical_slug": "qwen/qwen-2.5-72b-instruct",
      "hugging_face_id": "Qwen/Qwen2.5-72B-Instruct",
      "name": "Qwen2.5 72B Instruct",
      "created": 1726704000,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": "chatml"
      },
      "pricing": {
        "prompt": "0.00000012",
        "completion": "0.00000039"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "neversleep/llama-3.1-lumimaid-8b",
      "canonical_slug": "neversleep/llama-3.1-lumimaid-8b",
      "hugging_face_id": "NeverSleep/Lumimaid-v0.2-8B",
      "name": "NeverSleep: Lumimaid v0.2 8B",
      "created": 1726358400,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0.00000009",
        "completion": "0.0000006"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "cohere/command-r-08-2024",
      "canonical_slug": "cohere/command-r-08-2024",
      "hugging_face_id": null,
      "name": "Cohere: Command R (08-2024)",
      "created": 1724976000,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Cohere",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000015",
        "completion": "0.0000006"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 4000,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "cohere/command-r-plus-08-2024",
      "canonical_slug": "cohere/command-r-plus-08-2024",
      "hugging_face_id": null,
      "name": "Cohere: Command R+ (08-2024)",
      "created": 1724976000,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Cohere",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000025",
        "completion": "0.00001"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 4000,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "sao10k/l3.1-euryale-70b",
      "canonical_slug": "sao10k/l3.1-euryale-70b",
      "hugging_face_id": "Sao10K/L3.1-70B-Euryale-v2.2",
      "name": "Sao10K: Llama 3.1 Euryale 70B v2.2",
      "created": 1724803200,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0.00000065",
        "completion": "0.00000075"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "qwen/qwen-2.5-vl-7b-instruct",
      "canonical_slug": "qwen/qwen-2-vl-7b-instruct",
      "hugging_face_id": "Qwen/Qwen2.5-VL-7B-Instruct",
      "name": "Qwen: Qwen2.5-VL 7B Instruct",
      "created": 1724803200,
      "context_length": 32768,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Qwen",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000002",
        "completion": "0.0000002"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "nousresearch/hermes-3-llama-3.1-70b",
      "canonical_slug": "nousresearch/hermes-3-llama-3.1-70b",
      "hugging_face_id": "NousResearch/Hermes-3-Llama-3.1-70B",
      "name": "Nous: Hermes 3 70B Instruct",
      "created": 1723939200,
      "context_length": 65536,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "chatml"
      },
      "pricing": {
        "prompt": "0.0000003",
        "completion": "0.0000003"
      },
      "top_provider": {
        "context_length": 65536,
        "max_completion_tokens": 65536,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "nousresearch/hermes-3-llama-3.1-405b:free",
      "canonical_slug": "nousresearch/hermes-3-llama-3.1-405b",
      "hugging_face_id": "NousResearch/Hermes-3-Llama-3.1-405B",
      "name": "Nous: Hermes 3 405B Instruct (free)",
      "created": 1723766400,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "chatml"
      },
      "pricing": {
        "prompt": "0",
        "completion": "0"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "nousresearch/hermes-3-llama-3.1-405b",
      "canonical_slug": "nousresearch/hermes-3-llama-3.1-405b",
      "hugging_face_id": "NousResearch/Hermes-3-Llama-3.1-405B",
      "name": "Nous: Hermes 3 405B Instruct",
      "created": 1723766400,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "chatml"
      },
      "pricing": {
        "prompt": "0.000001",
        "completion": "0.000001"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/chatgpt-4o-latest",
      "canonical_slug": "openai/chatgpt-4o-latest",
      "hugging_face_id": null,
      "name": "OpenAI: ChatGPT-4o",
      "created": 1723593600,
      "context_length": 128000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000005",
        "completion": "0.000015"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": "2026-02-17"
    },
    {
      "id": "sao10k/l3-lunaris-8b",
      "canonical_slug": "sao10k/l3-lunaris-8b",
      "hugging_face_id": "Sao10K/L3-8B-Lunaris-v1",
      "name": "Sao10K: Llama 3 8B Lunaris",
      "created": 1723507200,
      "context_length": 8192,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0.00000004",
        "completion": "0.00000005"
      },
      "top_provider": {
        "context_length": 8192,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-4o-2024-08-06",
      "canonical_slug": "openai/gpt-4o-2024-08-06",
      "hugging_face_id": null,
      "name": "OpenAI: GPT-4o (2024-08-06)",
      "created": 1722902400,
      "context_length": 128000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "text",
          "image",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000025",
        "completion": "0.00001",
        "input_cache_read": "0.00000125"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
        "web_search_options"
      ],
      "expiration_date": null
    },
    {
      "id": "meta-llama/llama-3.1-405b",
      "canonical_slug": "meta-llama/llama-3.1-405b",
      "hugging_face_id": "meta-llama/llama-3.1-405B",
      "name": "Meta: Llama 3.1 405B (base)",
      "created": 1722556800,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "none"
      },
      "pricing": {
        "prompt": "0.000004",
        "completion": "0.000004"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 32768,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "meta-llama/llama-3.1-8b-instruct",
      "canonical_slug": "meta-llama/llama-3.1-8b-instruct",
      "hugging_face_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "name": "Meta: Llama 3.1 8B Instruct",
      "created": 1721692800,
      "context_length": 16384,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0.00000002",
        "completion": "0.00000005"
      },
      "top_provider": {
        "context_length": 16384,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "meta-llama/llama-3.1-405b-instruct",
      "canonical_slug": "meta-llama/llama-3.1-405b-instruct",
      "hugging_face_id": "meta-llama/Meta-Llama-3.1-405B-Instruct",
      "name": "Meta: Llama 3.1 405B Instruct",
      "created": 1721692800,
      "context_length": 131000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0.000004",
        "completion": "0.000004"
      },
      "top_provider": {
        "context_length": 131000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "meta-llama/llama-3.1-70b-instruct",
      "canonical_slug": "meta-llama/llama-3.1-70b-instruct",
      "hugging_face_id": "meta-llama/Meta-Llama-3.1-70B-Instruct",
      "name": "Meta: Llama 3.1 70B Instruct",
      "created": 1721692800,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0.0000004",
        "completion": "0.0000004"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mistral-nemo",
      "canonical_slug": "mistralai/mistral-nemo",
      "hugging_face_id": "mistralai/Mistral-Nemo-Instruct-2407",
      "name": "Mistral: Mistral Nemo",
      "created": 1721347200,
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": "mistral"
      },
      "pricing": {
        "prompt": "0.00000002",
        "completion": "0.00000004"
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-4o-mini-2024-07-18",
      "canonical_slug": "openai/gpt-4o-mini-2024-07-18",
      "hugging_face_id": null,
      "name": "OpenAI: GPT-4o-mini (2024-07-18)",
      "created": 1721260800,
      "context_length": 128000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "text",
          "image",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000015",
        "completion": "0.0000006",
        "input_cache_read": "0.000000075"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
        "web_search_options"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-4o-mini",
      "canonical_slug": "openai/gpt-4o-mini",
      "hugging_face_id": null,
      "name": "OpenAI: GPT-4o-mini",
      "created": 1721260800,
      "context_length": 128000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "text",
          "image",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000015",
        "completion": "0.0000006",
        "input_cache_read": "0.000000075"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
        "web_search_options"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemma-2-27b-it",
      "canonical_slug": "google/gemma-2-27b-it",
      "hugging_face_id": "google/gemma-2-27b-it",
      "name": "Google: Gemma 2 27B",
      "created": 1720828800,
      "context_length": 8192,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": "gemma"
      },
      "pricing": {
        "prompt": "0.00000065",
        "completion": "0.00000065"
      },
      "top_provider": {
        "context_length": 8192,
        "max_completion_tokens": 2048,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "google/gemma-2-9b-it",
      "canonical_slug": "google/gemma-2-9b-it",
      "hugging_face_id": "google/gemma-2-9b-it",
      "name": "Google: Gemma 2 9B",
      "created": 1719532800,
      "context_length": 8192,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Gemini",
        "instruct_type": "gemma"
      },
      "pricing": {
        "prompt": "0.00000003",
        "completion": "0.00000009"
      },
      "top_provider": {
        "context_length": 8192,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "sao10k/l3-euryale-70b",
      "canonical_slug": "sao10k/l3-euryale-70b",
      "hugging_face_id": "Sao10K/L3-70B-Euryale-v2.1",
      "name": "Sao10k: Llama 3 Euryale 70B v2.1",
      "created": 1718668800,
      "context_length": 8192,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0.00000148",
        "completion": "0.00000148"
      },
      "top_provider": {
        "context_length": 8192,
        "max_completion_tokens": 8192,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "nousresearch/hermes-2-pro-llama-3-8b",
      "canonical_slug": "nousresearch/hermes-2-pro-llama-3-8b",
      "hugging_face_id": "NousResearch/Hermes-2-Pro-Llama-3-8B",
      "name": "NousResearch: Hermes 2 Pro - Llama-3 8B",
      "created": 1716768000,
      "context_length": 8192,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "chatml"
      },
      "pricing": {
        "prompt": "0.00000014",
        "completion": "0.00000014"
      },
      "top_provider": {
        "context_length": 8192,
        "max_completion_tokens": 8192,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mistral-7b-instruct",
      "canonical_slug": "mistralai/mistral-7b-instruct",
      "hugging_face_id": "mistralai/Mistral-7B-Instruct-v0.3",
      "name": "Mistral: Mistral 7B Instruct",
      "created": 1716768000,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": "mistral"
      },
      "pricing": {
        "prompt": "0.0000002",
        "completion": "0.0000002"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mistral-7b-instruct-v0.3",
      "canonical_slug": "mistralai/mistral-7b-instruct-v0.3",
      "hugging_face_id": "mistralai/Mistral-7B-Instruct-v0.3",
      "name": "Mistral: Mistral 7B Instruct v0.3",
      "created": 1716768000,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": "mistral"
      },
      "pricing": {
        "prompt": "0.0000002",
        "completion": "0.0000002"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "meta-llama/llama-guard-2-8b",
      "canonical_slug": "meta-llama/llama-guard-2-8b",
      "hugging_face_id": "meta-llama/Meta-Llama-Guard-2-8B",
      "name": "Meta: LlamaGuard 2 8B",
      "created": 1715558400,
      "context_length": 8192,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "none"
      },
      "pricing": {
        "prompt": "0.0000002",
        "completion": "0.0000002"
      },
      "top_provider": {
        "context_length": 8192,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": "2026-02-25"
    },
    {
      "id": "openai/gpt-4o-2024-05-13",
      "canonical_slug": "openai/gpt-4o-2024-05-13",
      "hugging_face_id": null,
      "name": "OpenAI: GPT-4o (2024-05-13)",
      "created": 1715558400,
      "context_length": 128000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "text",
          "image",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000005",
        "completion": "0.000015"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 4096,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
        "web_search_options"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-4o",
      "canonical_slug": "openai/gpt-4o",
      "hugging_face_id": null,
      "name": "OpenAI: GPT-4o",
      "created": 1715558400,
      "context_length": 128000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "text",
          "image",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000025",
        "completion": "0.00001",
        "input_cache_read": "0.00000125"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
        "web_search_options"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-4o:extended",
      "canonical_slug": "openai/gpt-4o",
      "hugging_face_id": null,
      "name": "OpenAI: GPT-4o (extended)",
      "created": 1715558400,
      "context_length": 128000,
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": [
          "text",
          "image",
          "file"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000006",
        "completion": "0.000018"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 64000,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
        "web_search_options"
      ],
      "expiration_date": null
    },
    {
      "id": "meta-llama/llama-3-70b-instruct",
      "canonical_slug": "meta-llama/llama-3-70b-instruct",
      "hugging_face_id": "meta-llama/Meta-Llama-3-70B-Instruct",
      "name": "Meta: Llama 3 70B Instruct",
      "created": 1713398400,
      "context_length": 8192,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0.00000051",
        "completion": "0.00000074"
      },
      "top_provider": {
        "context_length": 8192,
        "max_completion_tokens": 8000,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "meta-llama/llama-3-8b-instruct",
      "canonical_slug": "meta-llama/llama-3-8b-instruct",
      "hugging_face_id": "meta-llama/Meta-Llama-3-8B-Instruct",
      "name": "Meta: Llama 3 8B Instruct",
      "created": 1713398400,
      "context_length": 8192,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0.00000003",
        "completion": "0.00000004"
      },
      "top_provider": {
        "context_length": 8192,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mixtral-8x22b-instruct",
      "canonical_slug": "mistralai/mixtral-8x22b-instruct",
      "hugging_face_id": "mistralai/Mixtral-8x22B-Instruct-v0.1",
      "name": "Mistral: Mixtral 8x22B Instruct",
      "created": 1713312000,
      "context_length": 65536,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": "mistral"
      },
      "pricing": {
        "prompt": "0.000002",
        "completion": "0.000006"
      },
      "top_provider": {
        "context_length": 65536,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "microsoft/wizardlm-2-8x22b",
      "canonical_slug": "microsoft/wizardlm-2-8x22b",
      "hugging_face_id": "microsoft/WizardLM-2-8x22B",
      "name": "WizardLM-2 8x22B",
      "created": 1713225600,
      "context_length": 65535,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": "vicuna"
      },
      "pricing": {
        "prompt": "0.00000062",
        "completion": "0.00000062"
      },
      "top_provider": {
        "context_length": 65535,
        "max_completion_tokens": 8000,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-4-turbo",
      "canonical_slug": "openai/gpt-4-turbo",
      "hugging_face_id": null,
      "name": "OpenAI: GPT-4 Turbo",
      "created": 1712620800,
      "context_length": 128000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00001",
        "completion": "0.00003"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 4096,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "anthropic/claude-3-haiku",
      "canonical_slug": "anthropic/claude-3-haiku",
      "hugging_face_id": null,
      "name": "Anthropic: Claude 3 Haiku",
      "created": 1710288000,
      "context_length": 200000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Claude",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00000025",
        "completion": "0.00000125",
        "input_cache_read": "0.00000003",
        "input_cache_write": "0.0000003"
      },
      "top_provider": {
        "context_length": 200000,
        "max_completion_tokens": 4096,
        "is_moderated": true
      },
      "supported_parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mistral-large",
      "canonical_slug": "mistralai/mistral-large",
      "hugging_face_id": null,
      "name": "Mistral Large",
      "created": 1708905600,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000002",
        "completion": "0.000006"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-3.5-turbo-0613",
      "canonical_slug": "openai/gpt-3.5-turbo-0613",
      "hugging_face_id": null,
      "name": "OpenAI: GPT-3.5 Turbo (older v0613)",
      "created": 1706140800,
      "context_length": 4095,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000001",
        "completion": "0.000002"
      },
      "top_provider": {
        "context_length": 4095,
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-4-turbo-preview",
      "canonical_slug": "openai/gpt-4-turbo-preview",
      "hugging_face_id": null,
      "name": "OpenAI: GPT-4 Turbo Preview",
      "created": 1706140800,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00001",
        "completion": "0.00003"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 4096,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mistral-7b-instruct-v0.2",
      "canonical_slug": "mistralai/mistral-7b-instruct-v0.2",
      "hugging_face_id": "mistralai/Mistral-7B-Instruct-v0.2",
      "name": "Mistral: Mistral 7B Instruct v0.2",
      "created": 1703721600,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": "mistral"
      },
      "pricing": {
        "prompt": "0.0000002",
        "completion": "0.0000002"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "stop",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mixtral-8x7b-instruct",
      "canonical_slug": "mistralai/mixtral-8x7b-instruct",
      "hugging_face_id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "name": "Mistral: Mixtral 8x7B Instruct",
      "created": 1702166400,
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": "mistral"
      },
      "pricing": {
        "prompt": "0.00000054",
        "completion": "0.00000054"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "neversleep/noromaid-20b",
      "canonical_slug": "neversleep/noromaid-20b",
      "hugging_face_id": "NeverSleep/Noromaid-20b-v0.1.1",
      "name": "Noromaid 20B",
      "created": 1700956800,
      "context_length": 4096,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama2",
        "instruct_type": "alpaca"
      },
      "pricing": {
        "prompt": "0.000001",
        "completion": "0.00000175"
      },
      "top_provider": {
        "context_length": 4096,
        "max_completion_tokens": 2048,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "alpindale/goliath-120b",
      "canonical_slug": "alpindale/goliath-120b",
      "hugging_face_id": "alpindale/goliath-120b",
      "name": "Goliath 120B",
      "created": 1699574400,
      "context_length": 6144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama2",
        "instruct_type": "airoboros"
      },
      "pricing": {
        "prompt": "0.00000375",
        "completion": "0.0000075"
      },
      "top_provider": {
        "context_length": 6144,
        "max_completion_tokens": 1024,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_a",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openrouter/auto",
      "canonical_slug": "openrouter/auto",
      "hugging_face_id": null,
      "name": "Auto Router",
      "created": 1699401600,
      "context_length": 2000000,
      "architecture": {
        "modality": "text+image+file+audio+video->text+image",
        "input_modalities": [
          "text",
          "image",
          "audio",
          "file",
          "video"
        ],
        "output_modalities": [
          "text",
          "image"
        ],
        "tokenizer": "Router",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "-1",
        "completion": "-1"
      },
      "top_provider": {
        "context_length": null,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "reasoning_effort",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
        "web_search_options"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-4-1106-preview",
      "canonical_slug": "openai/gpt-4-1106-preview",
      "hugging_face_id": null,
      "name": "OpenAI: GPT-4 Turbo (older v1106)",
      "created": 1699228800,
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00001",
        "completion": "0.00003"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 4096,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-3.5-turbo-instruct",
      "canonical_slug": "openai/gpt-3.5-turbo-instruct",
      "hugging_face_id": null,
      "name": "OpenAI: GPT-3.5 Turbo Instruct",
      "created": 1695859200,
      "context_length": 4095,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": "chatml"
      },
      "pricing": {
        "prompt": "0.0000015",
        "completion": "0.000002"
      },
      "top_provider": {
        "context_length": 4095,
        "max_completion_tokens": 4096,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mistralai/mistral-7b-instruct-v0.1",
      "canonical_slug": "mistralai/mistral-7b-instruct-v0.1",
      "hugging_face_id": "mistralai/Mistral-7B-Instruct-v0.1",
      "name": "Mistral: Mistral 7B Instruct v0.1",
      "created": 1695859200,
      "context_length": 2824,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instruct_type": "mistral"
      },
      "pricing": {
        "prompt": "0.00000011",
        "completion": "0.00000019"
      },
      "top_provider": {
        "context_length": 2824,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "temperature",
        "top_k",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-3.5-turbo-16k",
      "canonical_slug": "openai/gpt-3.5-turbo-16k",
      "hugging_face_id": null,
      "name": "OpenAI: GPT-3.5 Turbo 16k",
      "created": 1693180800,
      "context_length": 16385,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.000003",
        "completion": "0.000004"
      },
      "top_provider": {
        "context_length": 16385,
        "max_completion_tokens": 4096,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "mancer/weaver",
      "canonical_slug": "mancer/weaver",
      "hugging_face_id": null,
      "name": "Mancer: Weaver (alpha)",
      "created": 1690934400,
      "context_length": 8000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama2",
        "instruct_type": "alpaca"
      },
      "pricing": {
        "prompt": "0.00000075",
        "completion": "0.000001"
      },
      "top_provider": {
        "context_length": 8000,
        "max_completion_tokens": 2000,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_a",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "undi95/remm-slerp-l2-13b",
      "canonical_slug": "undi95/remm-slerp-l2-13b",
      "hugging_face_id": "Undi95/ReMM-SLERP-L2-13B",
      "name": "ReMM SLERP 13B",
      "created": 1689984000,
      "context_length": 6144,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama2",
        "instruct_type": "alpaca"
      },
      "pricing": {
        "prompt": "0.00000045",
        "completion": "0.00000065"
      },
      "top_provider": {
        "context_length": 6144,
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_a",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "gryphe/mythomax-l2-13b",
      "canonical_slug": "gryphe/mythomax-l2-13b",
      "hugging_face_id": "Gryphe/MythoMax-L2-13b",
      "name": "MythoMax 13B",
      "created": 1688256000,
      "context_length": 4096,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Llama2",
        "instruct_type": "alpaca"
      },
      "pricing": {
        "prompt": "0.00000006",
        "completion": "0.00000006"
      },
      "top_provider": {
        "context_length": 4096,
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_a",
        "top_k",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-4-0314",
      "canonical_slug": "openai/gpt-4-0314",
      "hugging_face_id": null,
      "name": "OpenAI: GPT-4 (older v0314)",
      "created": 1685232000,
      "context_length": 8191,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00003",
        "completion": "0.00006"
      },
      "top_provider": {
        "context_length": 8191,
        "max_completion_tokens": 4096,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-4",
      "canonical_slug": "openai/gpt-4",
      "hugging_face_id": null,
      "name": "OpenAI: GPT-4",
      "created": 1685232000,
      "context_length": 8191,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.00003",
        "completion": "0.00006"
      },
      "top_provider": {
        "context_length": 8191,
        "max_completion_tokens": 4096,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    },
    {
      "id": "openai/gpt-3.5-turbo",
      "canonical_slug": "openai/gpt-3.5-turbo",
      "hugging_face_id": null,
      "name": "OpenAI: GPT-3.5 Turbo",
      "created": 1685232000,
      "context_length": 16385,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "GPT",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000005",
        "completion": "0.0000015"
      },
      "top_provider": {
        "context_length": 16385,
        "max_completion_tokens": 4096,
        "is_moderated": true
      },
      "supported_parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p"
      ],
      "expiration_date": null
    }
  ]
}